<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[西蒙GIE部署文档]]></title>
    <url>%2Fxm.html</url>
    <content type="text"><![CDATA[设计原则部署要求充分考虑有效资源集中整合、优化的原则，便于日后实现系统的统一规划、应用、管理，从而实现资源的有效共享，在做到集中整合的同时，充分实现高可靠、高可用、高稳定、高性能和易扩展的要求。主要围绕以下目标开展： 集中化的基础服务 系统充分解耦 易于调配的硬件资源，按需分配 易于运维管理 易于网络管理：如新应用的接入 重新梳理规划日志、存储空间，规划存储需求容量 系统架构 总体部署方案应用采用docker化部署，外部请求通过负载均衡接入，内部服务通过内网负载均衡访问。 nginx通过rpm安装，每天通过logrotate切割。 容器直接通过docker-compose部署，通过ansible实现自动化。 es通过源码部署，存放通信日志。 mongo通过源码部署，使用Replica Set一主两从的模式部署。 Redis和RDS(mysql)购买云服务。 rabbitmq使用docker启动，两台机做mirror双活模式。 网络规划 实例类型 服务地址 实例规格 带宽 端口 关联实例 intranet 192.168.0.152 性能保障型slb.s1.small 5G TCP: 15672 TCP: 5672 GIEM001 GIEM002 intranet 192.168.0.151 性能保障型slb.s1.small 5G TCP: 8500 TCP: 8600 GIEDB001 GIEDB002 GIEDB003 intranet 192.168.0.150 性能保障型slb.s1.small 5G TCP: 9200 GIEDB004 GIEDB005 GIEDB006 internet 47.102.254.120 性能保障型slb.s2.small 4M HTTPS: 443 GIEAPP004 GIEAPP005 intranet 192.168.0.149 性能保障型slb.s1.small 5G TCP: 1883 TCP: 8883 TCP: 8080 TCP: 8081 TCP: 8880 GIEAPP001 GIEAPP002 GIEAPP003 intranet 192.168.0.147 性能保障型slb.s1.small 5G TCP: 80 GIEAPP006 GIEAPP007 intranet 192.168.0.146 性能保障型slb.s1.small 5G TCP: 2017 TCP: 2018 TCP: 2019 GIEAPP008 GIEAPP009 internet 47.102.62.145 性能保障型slb.s2.medium 5M TCP: 1883 TCP: 8883 TCP: 8080 TCP: 8081 TCP: 8880 GIEAPP001 GIEAPP002 GIEAPP003 internet 47.102.254.59 性能保障型slb.s2.medium 5M TCP: 80 GIEAPP004 GIEAPP005 主机及系统规划主机规划其中gie-zabbix为跳板机。 名称 操作系统 IP CPU(核) 内存(G) 数据盘(G) 所在可用区 GIEAPP001 Ubuntu18.04 47.103.151.136(外) 192.168.0.118 4 16 200 cn-shanghai-e GIEAPP002 Ubuntu18.04 47.103.146.67(外) 192.168.0.108 4 16 200 cn-shanghai-e GIEAPP003 Ubuntu18.04 47.103.95.210(外) 192.168.0.111 4 16 200 cn-shanghai-e GIEAPP004 Ubuntu18.04 47.103.140.119(外) 192.168.0.116 4 16 200 cn-shanghai-e GIEAPP005 Ubuntu18.04 47.103.79.9(外) 192.168.0.112 4 16 200 cn-shanghai-e GIEAPP006 Ubuntu18.04 47.103.130.195(外) 192.168.0.125 4 16 200 cn-shanghai-e GIEAPP007 Ubuntu18.04 47.103.68.112(外) 192.168.0.109 4 16 200 cn-shanghai-e GIEAPP008 Ubuntu18.04 47.103.155.115(外) 192.168.0.131 4 16 200 cn-shanghai-e GIEAPP009 Ubuntu18.04 47.103.68.14(外) 192.168.0.110 4 16 200 cn-shanghai-e GIEDB001 Ubuntu18.04 47.103.65.237(外) 192.168.0.122 8 32 500 cn-shanghai-e GIEDB002 Ubuntu18.04 47.103.138.200(外) 192.168.0.114 8 32 500 cn-shanghai-e GIEDB003 Ubuntu18.04 47.103.146.195(外) 192.168.0.119 8 32 500 cn-shanghai-e GIEDB004 Ubuntu18.04 47.103.89.44(外) 192.168.0.129 8 32 500 cn-shanghai-e GIEDB005 Ubuntu18.04 47.103.93.55(外) 192.168.0.132 8 32 500 cn-shanghai-e GIEDB006 Ubuntu18.04 47.103.91.216(外) 192.168.0.133 8 32 500 cn-shanghai-e GIEM001 Ubuntu18.04 47.103.150.57(外) 192.168.0.107 8 16 200 cn-shanghai-e GIEM002 Ubuntu18.04 47.103.91.116(外) 192.168.0.124 8 16 200 cn-shanghai-e GIEM003 Ubuntu18.04 47.103.88.252(外) 192.168.0.117 8 16 200 cn-shanghai-e GIEM004 Ubuntu18.04 47.103.146.134(外) 192.168.0.128 8 16 200 cn-shanghai-e gie-zabbix Ubuntu18.04 47.103.130.96(外) 192.168.0.121 4 16 500 cn-shanghai-e 系统参数优化 最大进程数配置 1234567添加或更新/etc/security/limits.conf配置#* soft nofile 65535#* hard nofile 65535soft nofile 1000001hard nofile 1000001hard openfile 1000001soft openfile 1000001 修改用户配置 123添加或更新用户root目录下的.profile配置ulimit -u 1000000 # root用户增加，程序用户不加ulimit -n 1000000 # root用户增加 sysctl参数调优在/etc/sysctl.conf尾部添加以下配置并加载 sysctl -p，阿里云主机已做系统优化，可不修改。 1234567891011121314151617net.ipv4.ip_local_port_range=1024 65000net.core.somaxconn = 10240net.ipv4.tcp_max_syn_backlog = 16384net.ipv4.tcp_syncookies = 1 # 重点优化net.core.netdev_max_backlog = 41960net.ipv4.tcp_max_tw_buckets = 3000net.ipv4.tcp_tw_reuse = 0net.ipv4.tcp_tw_recycle = 0net.ipv4.tcp_keepalive_intvl = 30net.ipv4.tcp_keepalive_time = 900net.ipv4.tcp_keepalive_probes = 3net.ipv4.tcp_fin_timeout = 15 net.ipv4.tcp_max_orphans = 13107net.core.optmem_max = 819200net.ipv4.tcp_mem = 262144 786432 786432net.ipv4.tcp_rmem = 4096 262144 16777216net.ipv4.tcp_wmem = 4096 262144 16777216 用户及用户组规划 用户组名称 用户组id 用户名称 用户id 帐号权限 simon 1000 simonuser 1001 程序帐号，用于服务更新发布 es 1001 simonuser 1002 elasticsearch维护，只在es部署主机创建 www-data 系统生成 www-data 系统生成 nginx程序帐号，源安装时自动创建 mongodb 系统生成 mongodb 系统生成 mongo程序帐号，源安装时自动创建 zabbix 系统生成 zabbix 系统生成 zabbix程序帐号，源安装时自动创建 docker 系统生成 docke用户组，源安装时自动创建 服务列表 服务名称 版本号 部署方式 部署主机 mysql 5.6 阿里云服务 mongo 3.2 源安装 GIEDB001 GIEDB002 GIEDB003 redis 2.8 阿里云服务 elasticsearch v5.6.16 原码部署 GIEDB004 GIEDB005 GIEDB006 rabbitmq rabbitmq:3.7.14-management docker-compose GIEM001 GIEM002 nginx 1.16.1 源安装 GIEAPP004 GIEAPP005 GIEAPP006 GIEAPP007 GIEAPP008 GIEAPP009 consul-server consul:1.5.0 docker-compose GIEDB001 GIEDB002 GIEDB003 consul-client consul:1.5.0 docker-compose 所有主机 ELK 6.7.0 阿里云服务 site srv_gie_site:gie.0.8.13 docker-compose GIEAPP004 GIEAPP005 gwapi srv_gwapi:gie.2.85.6 docker-compose GIEAPP004 GIEAPP005 ota srv_gw_ota_service:gie.0.9.7 docker-compose GIEAPP004 GIEAPP005 pushota srv_gw_ota_service:gie.0.9.7 docker-compose GIEAPP005 entapi srv_enterprise:gie.0.18.6 docker-compose GIEAPP004 GIEAPP005 innerapi srv_innerapi:gie.0.28.3 docker-compose GIEAPP006 GIEAPP007 celery_beat srv_gwapi:gie.2.85.6 docker-compose GIEAPP006 celery_worker srv_gwapi:gie.2.85.6 docker-compose GIEAPP006 GIEAPP007 active_email giz_la:gie.1.3.3 docker-compose GIEAPP007 la srv_gwapi:gie.2.85.6 docker-compose GIEM003 GIEM004 dev_latest giz_la:gie.1.3.3 docker-compose GIEM003 GIEM004 m2m_core gie_docker_m2m_core:v1.3.0 docker-compose GIEAPP001 GIEAPP002 GIEAPP003 m2m_ws docker_m2m_ws:v3.3.0 docker-compose GIEAPP001 GIEAPP002 GIEAPP003 m2m_ota docker_m2m_ota:v3.0.0 docker-compose GIEAPP001 GIEAPP002 GIEAPP003 snoti_proxy docker_snoti_proxy:v0.3.0 docker-compose GIEAPP008 GIEAPP009 snoti_busi docker_snoti_busi:v0.13.0 docker-compose GIEAPP008 GIEAPP009 snoti_http docker_snoti_http:v0.2.0 docker-compose GIEAPP008 GIEAPP009 snoti_xservice docker_snoti_xservice:v0.1.3 docker-compose GIEAPP008 GIEAPP009 kv_app consumer_raw_kv:v2.1.0 docker-compose GIEM003 GIEM004 kv_dev consumer_raw_kv:v2.1.0 docker-compose GIEM003 GIEM004 raw_app consumer_raw_kv:v2.1.0 docker-compose GIEM003 GIEM004 raw_dev consumer_raw_kv:v2.1.0 docker-compose GIEM003 GIEM004 mgmt es_mgmt:v2.2.0 docker-compose GIEM003 aggregateapi g-es-aggregate:1.0.8 docker-compose GIEAPP004 GIEAPP005 rtdataapi rt_data_api:v1.4.0 docker-compose GIEM003 GIEM004 oauth2 oauth2-server:1.0.0 docker-compose GIEAPP004 GIEAPP005 voice_converter instruction-converter:0.15.4 docker-compose GIEAPP004 GIEAPP005 voice_processor instruction-processor:0.10.5 docker-compose GIEAPP004 GIEAPP005 voice_editor instruction-editor:1.5.2 docker-compose GIEAPP004 GIEAPP005 voice_subscriber tparty-platform-pusher:0.2.1 docker-compose GIEAPP004 GIEAPP005 d3_notiapi notification_api:gie.1.3.0 docker-compose GIEAPP008 GIEAPP009 d3_reapi re_api:gie.0.5.2 docker-compose GIEAPP008 GIEAPP009 d3_recore re_processor:gie.0.4.7 docker-compose GIEAPP008 GIEAPP009 d3_recore_data re_processor:gie.0.4.7 docker-compose GIEAPP008 GIEAPP009 d3_noti_push notification_consumer:gie.1.2.4 docker-compose GIEAPP008 GIEAPP009 d3_noti_sms notification_consumer:gie.1.2.4 docker-compose GIEAPP008 GIEAPP009 d3_noti_http notification_consumer:gie.1.2.4 docker-compose GIEAPP008 GIEAPP009 d3_noti_email notification_consumer:gie.1.2.4 docker-compose GIEAPP008 GIEAPP009 backupfile data-backup:v0.0.6 docker-compose GIEM004 iotparser iot-parser:0.5.5 docker-compose GIEAPP006 GIEAPP007 productmetadata product-metadata:0.2.0 docker-compose GIEAPP006 GIEAPP007 devicedataaccessor devicesdata-accessor:0.4.3 docker-compose GIEAPP006 GIEAPP007 devicecontroller device-remote-control:0.5.7 docker-compose GIEAPP006 GIEAPP007 详细部署说明ansible安装和配置服务说明用于自动化运维批量管理和应用发布。 ansible安装1234apt updateapt install software-properties-commonapt-add-repository --yes --update ppa:ansible/ansibleapt install ansible ansible配置 将ssh-key的公钥配置到每台机/root/.ssh/authorized_keys下，以gie-zabbix为跳板机，配置成免密登陆。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150配置 /root/.ssh/configHost gie-zabbix IdentityFile /root/.ssh/gie_access_key.pem Port 22 HostName 192.168.0.121 User rootHost GIEAPP001 IdentityFile /root/.ssh/gie_access_key.pem Port 22 HostName 192.168.0.118 User rootHost GIEAPP002 IdentityFile /root/.ssh/gie_access_key.pem Port 22 HostName 192.168.0.108 User rootHost GIEAPP003 IdentityFile /root/.ssh/gie_access_key.pem Port 22 HostName 192.168.0.111 User rootHost GIEAPP004 IdentityFile /root/.ssh/gie_access_key.pem Port 22 HostName 192.168.0.116 User rootHost GIEAPP005 IdentityFile /root/.ssh/gie_access_key.pem Port 22 HostName 192.168.0.112 User rootHost GIEAPP006 IdentityFile /root/.ssh/gie_access_key.pem Port 22 HostName 192.168.0.125 User rootHost GIEAPP007 IdentityFile /root/.ssh/gie_access_key.pem Port 22 HostName 192.168.0.109 User rootHost GIEAPP008 IdentityFile /root/.ssh/gie_access_key.pem Port 22 HostName 192.168.0.131 User rootHost GIEAPP009 IdentityFile /root/.ssh/gie_access_key.pem Port 22 HostName 192.168.0.110 User rootHost GIEDB001 IdentityFile /root/.ssh/gie_access_key.pem Port 22 HostName 192.168.0.122 User rootHost GIEDB002 IdentityFile /root/.ssh/gie_access_key.pem Port 22 HostName 192.168.0.114 User rootHost GIEDB003 IdentityFile /root/.ssh/gie_access_key.pem Port 22 HostName 192.168.0.119 User rootHost GIEDB004 IdentityFile /root/.ssh/gie_access_key.pem Port 22 HostName 192.168.0.129 User rootHost GIEDB005 IdentityFile /root/.ssh/gie_access_key.pem Port 22 HostName 192.168.0.132 User rootHost GIEDB006 IdentityFile /root/.ssh/gie_access_key.pem Port 22 HostName 192.168.0.133 User rootHost GIEM001 IdentityFile /root/.ssh/gie_access_key.pem Port 22 HostName 192.168.0.107 User rootHost GIEM002 IdentityFile /root/.ssh/gie_access_key.pem Port 22 HostName 192.168.0.124 User rootHost GIEM003 IdentityFile /root/.ssh/gie_access_key.pem Port 22 HostName 192.168.0.117 User rootHost GIEM004 IdentityFile /root/.ssh/gie_access_key.pem Port 22 HostName 192.168.0.128 User rootHost SAASAPP001 IdentityFile /root/.ssh/gie_access_key.pem Port 22 HostName 192.168.0.113 User rootHost SAASAPP002 IdentityFile /root/.ssh/gie_access_key.pem Port 22 HostName 192.168.0.130 User rootHost SAASRABBIT001 IdentityFile /root/.ssh/gie_access_key.pem Port 22 HostName 192.168.0.134 User rootHost SAASRABBIT002 IdentityFile /root/.ssh/gie_access_key.pem Port 22 HostName 192.168.0.115 User rootHost SAASSnoti IdentityFile /root/.ssh/gie_access_key.pem Port 22 HostName 192.168.0.127 User root 配置ansible主机角色 12345678910111213141516171819202122232425262728293031/etc/ansible/hosts[all:vars]ansible_python_interpreter=/usr/bin/python3[GIE]GIEAPP001GIEAPP002GIEAPP003GIEAPP004GIEAPP005GIEAPP006GIEAPP007GIEAPP008GIEAPP009GIEDB001GIEDB002GIEDB003GIEDB004GIEDB005GIEDB006GIEM001GIEM002GIEM003GIEM004[SAAS]SAASAPP001SAASAPP002SAASRABBIT001SAASRABBIT002SAASSnoti 每台机创建simon用户组及simonuser程序帐号 123456789#切换到gie-zabbix主机的simonuser帐号创建ssh-key,做成免密登陆。ssh-keygen#切换到root帐号，为每台主机创建simonuser帐号ansible all -m group -a &apos;name=simon gid=1000 state=present&apos;ansible all -m user -a &quot;name=simonuser uid=1001 group=simon shell=/bin/bash&quot;ansible all -m file -a &quot;path=/home/simonuser/.ssh state=directory mode=&apos;0700&apos; group=simon owner=simonuser&quot;ansible all -m copy -a &quot;src=/home/simonuser/.ssh/authorized_keys dest=/home/simonuser/.ssh/&quot;ansible all -m copy -a &quot;src=/etc/sudoers.d/simonuser dest=/etc/sudoers.d/&quot; ansible-playbook配置说明123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124auto_deployment├── environments│ ├── group_vars│ │ └── gizwits_vars.yml # 通用配置文件│ ├── hosts # 部署服务对应主机配置│ └── playbooks # 剧本文件│ ├── active_email.yml│ ├── aggregateapi.yml│ ├── backupfile.yml│ ├── celery_beat.yml│ ├── celery_worker.yml│ ├── consul_client.yml│ ├── consul_server.yml│ ├── d3_notiapi.yml│ ├── d3_noti_email.yml│ ├── d3_noti_http.yml│ ├── d3_noti_push.yml│ ├── d3_noti_sms.yml│ ├── d3_reapi.yml│ ├── d3_recore_data.yml│ ├── d3_recore.yml│ ├── devicecontroller.yml│ ├── devicedataaccessor.yml│ ├── dev_latest.yml│ ├── entapi.yml│ ├── gwapi.yml│ ├── innerapi.yml│ ├── iotparser.yml│ ├── la.yml│ ├── m2m_core.yml│ ├── m2m_ota.yml│ ├── m2m_ws.yml│ ├── oauth2.yml│ ├── ota.yml│ ├── productmetadata.yml│ ├── pushota.yml│ ├── rabbitmq.yml│ ├── rtbd_kv_app.yml│ ├── rtbd_kv_dev.yml│ ├── rtbd_mgmt.yml│ ├── rtbd_raw_app.yml│ ├── rtbd_raw_dev.yml│ ├── rtdataapi.yml│ ├── site.yml│ ├── snoti_busi.yml│ ├── snoti_http.yml│ ├── snoti_proxy.yml│ ├── snoti_xservice.yml│ ├── voice_converter.yml│ ├── voice_editor.yml│ ├── voice_processor.yml│ └── voice_subscriber.yml└── roles ├── active_email │ ├── defaults # default variables for the role. │ │ └── main.yml │ ├── handlers # contains handlers, which may be used by this role or even anywhere outside this role. │ │ └── main.yml │ ├── meta # defines some meta data for this role. │ │ └── main.yml │ ├── README.md │ ├── tasks # contains the main list of tasks to be executed by the role. │ │ └── main.yml │ ├── templates # contains templates which can be deployed via this role. │ │ ├── docker-compose.j2 │ │ ├── env │ │ └── init.sh │ └── vars # other variables for the role (see Using Variables for more information). │ └── main.yml ├── aggregateapi ├── backupfile ├── celery │ ├── beat │ └── worker ├── consul │ ├── client │ └── server ├── d3 │ ├── notiapi │ ├── noti_email │ ├── noti_http │ ├── noti_push │ ├── noti_sms │ ├── reapi │ ├── recore │ └── recore_data ├── devicecontroller ├── devicedataaccessor ├── dev_latest ├── entapi ├── es ├── gwapi ├── innerapi ├── iotparser ├── la ├── m2m │ ├── core │ ├── ota │ └── ws ├── oauth2 ├── ota ├── productmetadata ├── pushota ├── rabbitmq ├── rtbd │ ├── gendataapi │ ├── kv_app │ ├── kv_dev │ ├── mgmt │ ├── raw_app │ ├── raw_dev │ ├── rtdataapi │ └── xservice ├── site ├── snoti │ ├── busi │ ├── http │ ├── proxy │ └── xservice └── voice ├── converter ├── editor ├── processor └── subscriber ossutil安装和配置服务说明阿里云oss命令行工具，参考链接：https://help.aliyun.com/document_detail/120075.html 工具安装1234567891011cd /bin/wget http://gosspublic.alicdn.com/ossutil/1.6.9/ossutil64chmod 755 ossutil64ossutil64 config请输入配置文件名，文件名可以带路径（默认为：/home/user/.ossutilconfig，回车将使用默认路径。如果用户设置为其它路径，在使用命令时需要将--config-file选项设置为该路径）：未输入配置文件路径，将使用默认配置文件：/home/user/.ossutilconfig。对于下述配置，回车将跳过相关配置项的设置，配置项的具体含义，请使用&quot;help config&quot;命令查看。请输入endpoint：http://oss-cn-shenzhen.aliyuncs.com请输入accessKeyID：yourAccessKeyID请输入accessKeySecret：yourAccessKeySecret请输入stsToken： 可不填写 docker安装和配置服务说明用于PaaS容器部署，使用docker-compose直接启动，不涉及swarm及k8s部署。 docker安装由于使用海外的官方源安装可能时间较长，建议直接登陆每台主机直接安装。123456apt-get updateapt-get install apt-transport-https ca-certificates curl gnupg-agent software-properties-common -ycurl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -add-apt-repository &quot;deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable&quot;apt-get updateapt-get install docker-ce docker-ce-cli containerd.io -y docker-compose安装12curl -L &quot;https://github.com/docker/compose/releases/download/1.23.2/docker-compose-$(uname -s)-$(uname -m)&quot; -o /usr/local/bin/docker-composechmod +x /usr/local/bin/docker-compose docker配置1234567891011121. /etc/docker/daemon.json&#123; &quot;graph&quot;: &quot;/data/docker&quot;, &quot;userland-proxy&quot;: false, &quot;log-driver&quot;: &quot;json-file&quot;, &quot;log-opts&quot;: &#123; &quot;max-size&quot;: &quot;512m&quot;, &quot;max-file&quot;: &quot;3&quot; &#125;&#125;2. service docker restart mysql安装和配置服务说明 推荐购买云RDS，数据库版本要求为mysql5.6.x版本，不能使用5.7以上版本。 用于存放paas配置类型数据，例如product_key，APP，规则配置，m2m、api流控限制等数据。 mysql配置 创建数据库 12345678CREATE DATABASE xcloud DEFAULT CHARACTER SET utf8;CREATE DATABASE m2m DEFAULT CHARACTER SET utf8;CREATE DATABASE push_engine DEFAULT CHARACTER SET utf8;CREATE DATABASE rules_engine DEFAULT CHARACTER SET utf8;CREATE DATABASE tparty_voice DEFAULT CHARACTER SET utf8;CREATE DATABASE oauth2_server DEFAULT CHARACTER SET utf8;CREATE DATABASE devices_data DEFAULT CHARACTER SET utf8;CREATE DATABASE parser_data DEFAULT CHARACTER SET utf8; 创建用户和赋权大部份应用通过python开发，数据的migrate是通过django框架完成，数据库用户需要有表的增加、删除、修改权限。 123456789grant all on xcloud.* to &apos;用户名&apos;@&apos;%&apos; grant all on m2m.* to &apos;用户名&apos;@&apos;%&apos; grant all on push_engine.* to &apos;用户名&apos;@&apos;%&apos; grant all on rules_engine.* to &apos;用户名&apos;@&apos;%&apos; grant all on rule_script.* to &apos;用户名&apos;@&apos;%&apos; grant all on tparty_voice.* to &apos;用户名&apos;@&apos;%&apos; grant all on oauth2_server.* to &apos;用户名&apos;@&apos;%&apos; grant all on devices_data.* to &apos;用户名&apos;@&apos;%&apos; grant all on parser_data.* to &apos;用户名&apos;@&apos;%&apos; 备份策略每周一、三、五、七凌晨1:00至2:00. 网络安全设置只限内网主机使用 mongo安装和配置服务说明用于保存平台状态变化类型数据，例如设备状态、ota状态，用户状态等。 mongo安装12345678wget -qO - https://www.mongodb.org/static/pgp/server-3.2.asc | sudo apt-key add -echo &quot;deb [ arch=amd64 ] https://repo.mongodb.org/apt/ubuntu trusty/mongodb-org/3.2 multiverse&quot; | sudo tee /etc/apt/sources.list.d/mongodb-org-3.2.listapt-get install -y mongodb-orgecho &quot;mongodb-org hold&quot; | sudo dpkg --set-selectionsecho &quot;mongodb-org-server hold&quot; | sudo dpkg --set-selectionsecho &quot;mongodb-org-shell hold&quot; | sudo dpkg --set-selectionsecho &quot;mongodb-org-mongos hold&quot; | sudo dpkg --set-selectionsecho &quot;mongodb-org-tools hold&quot; | sudo dpkg --set-selections mongo配置 实例配置 123456789101112131415161718192021222324252627282930313233# /etc/mongod.conf# for documentation of all options, see:# http://docs.mongodb.org/manual/reference/configuration-options/storage: dbPath: /data/mongodb/data directoryPerDB: true journal: enabled: true engine: wiredTiger wiredTiger: engineConfig: cacheSizeGB: 18 directoryForIndexes: true collectionConfig: blockCompressor: zlib indexConfig: prefixCompression: truesystemLog: destination: file logAppend: true path: /data/mongodb/logs/mongod.lognet: port: 27017 maxIncomingConnections: 20000processManagement: fork: truesecurity: keyFile: /data/mongodb/certs/mongodb.key authorization: enabledreplication: oplogSizeMB: 25000 replSetName: rs0 主机名配置 1234# /etc/hosts192.168.0.122 GIEDB001 192.168.0.114 GIEDB002192.168.0.119 GIEDB003 启动方式 1su - mongodb -s /bin/bash -c &quot;mongod --config /etc/mongod.conf&quot; 集群配置参考 https://docs.mongodb.com/v3.2/core/replica-set-members/ 123cfg = &#123;_id : &quot;rs0&quot;,members : [ &#123; _id:0, host:&quot;GIEDB001:27017&quot;, priority:2 &#125;,&#123; _id:1, host:&quot;GIEDB002:27017&quot;, priority:1 &#125;,&#123; _id:2, host:&quot;GIEDB003:27017&quot;, priority:1 &#125; ]&#125;rs.initiate(cfg) 创建数据库帐号密码: 1234567891011121314151617181920use admindb.createUser( &#123;user: &quot;admin&quot;,pwd: &quot;******&quot;,roles: [ &#123; role: &quot;userAdminAnyDatabase&quot;, db: &quot;admin&quot; &#125;,&#123; role: &quot;root&quot;, db: &quot;admin&quot; &#125; ]&#125;)use gizwits_coredb.createUser(&#123; user: &quot;core_user&quot;, pwd: &quot;******&quot;, roles: [&#123; role: &quot;readWrite&quot;, db: &quot;gizwits_core&quot; &#125;] &#125;)db.createUser(&#123; user: &quot;admin&quot;, pwd: &quot;******&quot;, roles: [&#123; role: &quot;readWrite&quot;, db: &quot;gizwits_core&quot; &#125;] &#125;)use gizwits_datadb.createUser(&#123; user: &quot;data_user&quot;, pwd: &quot;******&quot;, roles: [&#123; role: &quot;readWrite&quot;, db: &quot;gizwits_data&quot; &#125;] &#125;)db.createUser(&#123; user: &quot;admin&quot;, pwd: &quot;******&quot;, roles: [&#123; role: &quot;readWrite&quot;, db: &quot;gizwits_data&quot; &#125;] &#125;)use gizwits_eventdb.createUser(&#123; user: &quot;event_user&quot;, pwd: &quot;******&quot;, roles: [&#123; role: &quot;readWrite&quot;, db: &quot;gizwits_event&quot; &#125;] &#125;)db.createUser(&#123; user: &quot;admin&quot;, pwd: &quot;******&quot;, roles: [&#123; role: &quot;readWrite&quot;, db: &quot;gizwits_event&quot; &#125;] &#125;)use rawdb.createUser(&#123; user: &quot;raw_user&quot;, pwd: &quot;******&quot;, roles: [&#123; role: &quot;readWrite&quot;, db: &quot;raw&quot; &#125;] &#125;)db.createUser(&#123; user: &quot;admin&quot;, pwd: &quot;******&quot;, roles: [&#123; role: &quot;readWrite&quot;, db: &quot;raw&quot; &#125;] &#125;)use gizwits_analyticdb.createUser(&#123; user: &quot;analytic_user&quot;, pwd: &quot;******&quot;, roles: [&#123; role: &quot;readWrite&quot;, db: &quot;gizwits_analytic&quot; &#125;] &#125;)db.createUser(&#123; user: &quot;admin&quot;, pwd: &quot;******&quot;, roles: [&#123; role: &quot;readWrite&quot;, db: &quot;gizwits_analytic&quot; &#125;] &#125;) 备份策略每天凌晨1:00在GIEDB003主机上备份，并将备份文件打包上传到阿里云oss。 网络安全设置只限内网主机使用 es 安装和配置服务说明 用于存放通讯日志，包括raw和kv数据，默认保存3〜5天。 根据kv数据提供数据聚合能力。java安装12apt-get updateapt-get install openjdk-8-jdk 系统参数配置分别在GIEDB004､GIEDB005和GIEDB006主机新增配置。12echo &quot;vm.max_map_count=262144&quot; &gt;&gt; /etc/sysctl.confsysctl -p 主机名配置1234# /etc/hosts192.168.0.129 GIEDB004 192.168.0.132 GIEDB005192.168.0.133 GIEDB006 创建es程序帐号12ansible es -m group -a &apos;name=es gid=1001 state=present&apos;ansible es -m user -a &quot;name=es uid=1002 group=es shell=/bin/bash&quot; es安装12cd /data/workspace/auto_deploymentansible-playbook -i environments/hosts environments/playbooks/es.yml --tag=init es初始化12# 根据集群节点数量优化shard和replicaset配置/data/workspace/elasticsearch/es_init.sh 网络安全设置9200和9300主机端口只限集群节点主机访问。 rabbitmq 安装和配置服务说明消息中心间，用于PaaS平台内部消息流转，用docker-compose直接起动。设计上其中/log_data为PaaS平台默认vhost，通过log_data_user帐号维护，/ota为PaaS平台ota相关服务专有vhost，通过ota_user帐号维护。搭建时采用双节点镜像模式，为保护rabbitmq，队列长度需设置默认长度限制： vhost 队列 限制策略 权重 /log_data all queue 100000 0 /ota all queue 100000 0 /log_data gizwits_rt_data 100000 1 rabbitmq安装12cd /data/workspace/auto_deploymentansible-playbook -i environments/hosts environments/playbooks/rabbitmq.yml --tag=init rabbitmq初始化帐号密码1docker-compose exec rabbitmq sh /backup/init.sh rabbitmq集群配置1234567docker-compose -f /data/workspace/rabbitmq/docker-compose.yml exec rabbitmq bashrabbitctl stop_apprabbitmqctl join_cluster --ram rabbit@GIEM001docker-compose exec rabbitmq rabbitmqctl stop_appdocker-compose exec rabbitmq rabbitmqctl join_cluster Supor@CNAZ08IOTdocker-compose exec rabbitmq rabbitmqctl start_apprabbitmqctl set_policy ha-all &quot;^&quot; &apos;&#123;&quot;ha-mode&quot;:&quot;all&quot;&#125;&apos; 网络安全设置5672端口为业务通讯端口，只限内网主机访问。15672端口为api接口使用端口，WebUI也使用该端口进行管理，为方便维护操作，外网访问15672端口可增设IP白名单限制。 consul 安装和配置服务说明集中管理服务起动时使用的环境变量，使用key-value方式保存。consul分为服务端和客户端，服务端使用三台主机搭建集群，其中8500为http接口,8600为NDS接口,客户端会使用。服务读取consul配置时会连接本机的consul客户端程序，读取指定的配置数据。 consul 安装12cd /data/workspace/auto_deploymentansible-playbook -i environments/hosts environments/playbooks/rabbitmq.yml --tag=init 网络安全设置consul web ui需通过8500端口访问，可指定外网IP访问，并增设nginx用户名密码作为安全代理。内网主机可默认开放。 redis安装和配置服务说明推荐购买云redis，版本要求为2.8以上3.2以下，不支持集群版。 网络安全设置只限内网访问。 nginx安装和配置nginx安装1234apt-get install software-properties-common add-apt-repository ppa:nginx/stable apt-get updateapt-get install nginx -y nginx配置 nginx统一配置修改把nginx.conf解压到GIEAPP04至09主机的/etc/nginx/下，包括certs证书文件。 验证 123nginx -tnginx: the configuration file /etc/nginx/nginx.conf syntax is oknginx: configuration file /etc/nginx/nginx.conf test is successful 启动nginx 1/etc/init.d/nginx start ELK安装和配置服务说明推荐购买云服务，版本不限。 es配置自动创建索引:允许自动创建索引删除索引指定名称:删除时索引名称支持通配符 logstash配置123456789101112131415161718input &#123; tcp &#123; port =&gt; 8050 codec =&gt; json_lines &#125;&#125;filter &#123;&#125;output &#123; elasticsearch &#123; hosts =&gt; [&quot;es-cn-v0h1ds25m0021zv8j.elasticsearch.aliyuncs.com:9200&quot;] user =&gt; &quot;simonuser&quot; password =&gt; &quot;Simonss2019&quot; index =&gt; &quot;logstash-m2m-%&#123;+YYYY.MM.dd&#125;&quot; codec =&gt; json_lines &#125;&#125; OpenAPI服务安装和配置服务说明gwapi作为API网关，提供设备接入、用户账号管理、用户与设备绑定管理、设备远程监控、定时任务以及设备高级数据等服务。active_email、celery_beat、celery_worker作为gwapi的扩展服务.active_email为激活邮件发送服务，当app用户通过gwapi注册时会使用，通过saas注册时无需部署。celery_beat和celery_worker为定时任务服务，定时任应该有三种，设备分组定时，场景定时，单个设备did定时任务。gwapi接收到定时任务请求时会将相关任务写到redis，celery_beat会接收任务并通知worker处理。当场景定时由saas实现时，这两个服务可以不用部署。 服务部署应用发布12345cd /data/workspace/auto_deploymentansible-playbook -i environments/hosts environments/playbooks/gwapi.yml --tag=initansible-playbook -i environments/hosts environments/playbooks/active_email.yml --tag=initansible-playbook -i environments/hosts environments/playbooks/celery_beat.yml --tag=initansible-playbook -i environments/hosts environments/playbooks/celery_worker.yml --tag=init 数据库初始化只需要在应用部署的其中一台主机做一次。123docker-compose -f /data/workspace/gwapi/docker-compose.yml bash/env-gwapi/bin/python manage.py migrate --ignore/env-gwapi/bin/python manage.py createsuperuser 网络安全设备服务通过负载均衡访问，只需开放主机的80和443端口。 注意事项consul中应用配置发生变化时需重启相关容器生效。celery_beat和celery_worker部署时，worker可以启多个，但beat只能启动一个。 site服务安装和配置服务说明开发者中心用于配置产品、产品数据点、APP、D3规则引擎、Snoti等应用模块，产品上线前用户可在开发者中心通过虚拟设备进行开发和调试，同时开者中心可维护m2m地址及邮箱等基础服务配置。 服务部署应用发布12cd /data/workspace/auto_deploymentansible-playbook -i environments/hosts environments/playbooks/site.yml --tag=init 数据库初始化只需要在应用部署的其中一台主机做一次。12docker-compose -f /data/workspace/site/docker-compose.yml bashpython manage.py migrate --ignore 网络安全设备服务通过负载均衡访问，只需开放主机的80和443端口。 注意事项consul中应用配置发生变化时需重启相关容器生效。 innerapi服务安装和配置服务说明内部RESTful API接口，用于产品管理，用户管理，设备管理等服务。 服务部署应用发布12cd /data/workspace/auto_deploymentansible-playbook -i environments/hosts environments/playbooks/innerapi.yml --tag=init 网络安全设备主机只需内网负载均衡访问，无需开放外部端口。 注意事项consul中应用配置发生变化时需重启相关容器生效。 ota服务安装和配置服务说明ota服务用于设备固件更新，包括两个服务组件：ota：开发者中心插件，同时也是ota下载的RESTful API，设备上线时会请求openapi,通过openapi转发到ota服务检查是否有固件需要更新，如有则发起请求下载。pushota：ota固件定时推送。 服务部署应用发布123cd /data/workspace/auto_deploymentansible-playbook -i environments/hosts environments/playbooks/ota.yml --tag=initansible-playbook -i environments/hosts environments/playbooks/pushota.yml --tag=init 网络安全设备主机只需内网负载均衡访问，无需开放外部端口。 注意事项consul中应用配置发生变化时需重启相关容器生效。openapi后台配置ota服务地址直接配置ota服务名称，服务之间通过docker网络自动查找。xservice部署时，xservice_id和key需与开发者中心配置一致。pushota只能启动一个。 通讯日志服务安装和配置服务说明通讯日志服务订阅rabbitmq里的raw和kv数据，按ES模板配置写入ES里，为开发者中心、企业API、openAPI提供通讯日志查询和数据点聚合功能。rtdataapi: 通讯日志查询接口。aggregateapi: 数据数据查询接口。rtdata_kv_app: consumer，从rabbitmq中订阅la解释后的app2dev数据，并写入ES中。rtdata_kv_dev: consumer，从rabbitmq中订阅la解释后的dev2app数据，并写入ES中。rtdata_raw_app: consumer，从rabbitmq中订阅app2dev的原始raw数据，并写入ES中。rtdata_raw_dev: consumer，从rabbitmq中订阅dev2app的原始raw数据，并写入ES中。rtdata_mgmt: consumer，按模板规则生成indices数据库。 服务部署应用发布12345678cd /data/workspace/auto_deploymentansible-playbook -i environments/hosts environments/playbooks/rtdataapi.yml --tag=initansible-playbook -i environments/hosts environments/playbooks/aggregateapi.yml --tag=initansible-playbook -i environments/hosts environments/playbooks/rtbd_mgmt.yml --tag=initansible-playbook -i environments/hosts environments/playbooks/rtbd_kv_app.yml --tag=initansible-playbook -i environments/hosts environments/playbooks/rtbd_kv_dev.yml --tag=initansible-playbook -i environments/hosts environments/playbooks/rtbd_raw_app.yml --tag=initansible-playbook -i environments/hosts environments/playbooks/rtbd_raw_dev.yml --tag=init 网络安全设备主机只需内网负载均衡访问，无需开放外部端口。 注意事项无 M2M服务安装和配置服务说明m2m属设备连接层服务，包含三个服务组件，分别为m2m_core，m2m_ws，m2m_ota。 m2m_core负责维护设备及APP的长链接，以及设备/APP登陆鉴权、流控等。启动时依赖rabbitmq及mysql，服务启动后会暴露8081､1883､8883等三个端口，其中1883为mqtt端口，8883为mqtt(ssl)端口，8081为m2m的http_api接口，通常8081只做配置管理使用。 m2m_ws作为websocket接口层供微信、开发者中心等平台使用，其中8080为websocket端口，8880为websocket ssl端口，服务依赖于m2m_core，业务处理交由m2m_core实现。 m2m_ota负责处理设备ota推送信息，服务依赖于rabbitmq及m2m_core，平台有ota推送请求时相应的服务会往rabbitmq里推送相关的信息，m2m_ota接收到相关消息后会通知m2m_core，告诉符合推送要求的且正连在m2m_core的设备做ota更新操作。 m2m服务部署依赖服务初始化mysql数据库123456789101112131415161718192021222324# m2mCREATE TABLE `m2m_sec_quota_setting` ( `id` int(11) NOT NULL AUTO_INCREMENT, `domain_id` varchar(32) NOT NULL, `type` varchar(32) NOT NULL, `enabled` tinyint(1) NOT NULL, `quota` int(11) NOT NULL, `time_scope` int(11) NOT NULL, `min_time_login` int(11) DEFAULT NULL, `last_modified` bigint(20) NOT NULL, `updated_at` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP, PRIMARY KEY (`id`), UNIQUE KEY `domain_type` (`domain_id`,`type`)) ENGINE=InnoDB DEFAULT CHARSET=utf8;INSERT INTO m2m_sec_quota_setting (domain_id, type, enabled, quota, time_scope, min_time_login, last_modified) VALUES(&apos;default&apos;, &apos;m2m_sec_mqtt_msg_count&apos;, 1, 1800, 60, null, 10000), (&apos;default&apos;, &apos;m2m_sec_mqtt_msg_size&apos;, 1, 180000000, 60, null, 10000), (&apos;default&apos;, &apos;mqtt_login_count&apos;, 1, 60, 60, 15, 10000), (&apos;default&apos;, &apos;m2m_sec_data_msg_count&apos;, 1, 30, 60, null, 10000);CREATE TABLE noti_operator ( auth_id varchar(22) NOT NULL, auth_secret varchar(22) NOT NULL, product_key varchar(32) NOT NULL, type varchar(10) NOT NULL, tag text, created_at double DEFAULT NULL, PRIMARY KEY (auth_id), KEY product_key_index (product_key));CREATE TABLE noti_operator_device ( mac varchar(32) NOT NULL, auth_id varchar(22) NOT NULL, did varchar(22) NOT NULL, created_at double DEFAULT NULL, PRIMARY KEY (mac,auth_id)) ;CREATE TABLE noti_operator_permission ( auth_id varchar(32) NOT NULL, code varchar(32) NOT NULL, created_at double DEFAULT NULL, PRIMARY KEY (auth_id,code), KEY auth_id_index (auth_id));CREATE TABLE noti_subkey ( product_key varchar(32) NOT NULL, subkey varchar(32) NOT NULL, auth_id varchar(22) NOT NULL, created_at double DEFAULT NULL, PRIMARY KEY (product_key,subkey), KEY auth_id_index (auth_id)); 应用发布1234cd /data/workspace/auto_deploymentansible-playbook -i environments/hosts environments/playbooks/m2m_core.yml --tag=initansible-playbook -i environments/hosts environments/playbooks/m2m_ws.yml --tag=initansible-playbook -i environments/hosts environments/playbooks/m2m_ota.yml --tag=init 网络安全设备设置内网和外网负载均衡，通过TCP转TCP的方式转发到m2m服务的各个端口，主机只需针对1883､8883､8080､8880､8081等端口开放网络访问权限。 注意事项docker-compose.yml里的APP_M2M_ID需和开发者中心m2m配置的数据库id一致。 LA服务安装和配置服务说明LA为log analysis的缩写，包含dev_latest和la两个服务组件，服务无状态，可横向扩展。用户或设备通过M2M上报消息后，M2M会将raw数据写入rabbitmq转由LA处理，LA根据产品的数据点定义将raw数据解释kv数据，并将处理结果写入rabbitmq供其他业务模块使用。dev_latest会根据设备上报的消息更新设备在redis及mongo里的最新状态。 服务部署应用发布123cd /data/workspace/auto_deploymentansible-playbook -i environments/hosts environments/playbooks/la.yml --tag=initansible-playbook -i environments/hosts environments/playbooks/dev_latest.yml --tag=init entapi服务安装和配置服务说明entapi作为企业API网关，提供设备接入、设备绑定管理、设备远程监控以及设备高级数据等服务。 服务部署应用发布12cd /data/workspace/auto_deploymentansible-playbook -i environments/hosts environments/playbooks/entapi.yml --tag=init 数据库初始化只需要在应用部署的其中一台主机做一次。12docker-compose -f /data/workspace/entapi/docker-compose.yml bash/env-gwenter/bin/python manage.py migrate --ignore 网络安全设备服务通过负载均衡访问，只需开放主机的80和443端口。企业API在应用层支持IP白名单功能。 注意事项consul中应用配置发生变化时需重启相关容器生效。产品要通过企来API做远程控制，需和企业ID关联，并打开远程控制选项方可使用。 设备访问服务安装和配置服务说明维护设备数据的基础服务组件，负责底层设备相关数据的读取和写入。 服务部署应用发布12cd /data/workspace/auto_deploymentansible-playbook -i environments/hosts environments/playbooks/devicedataaccessor.yml --tag=init 数据库初始化只需要在应用部署的其中一台主机做一次。12docker-compose -f /data/workspace/devicedataaccessor/docker-compose.yml exec devicedataaccessor shpython manage.py migrate 网络安全设备无需开放外部端口 注意事项consul中应用配置发生变化时需重启相关容器生效。 设备控制服务安装和配置服务说明负责完成各种类型的设备控制，供Snoti调用。 服务部署应用发布12cd /data/workspace/auto_deploymentansible-playbook -i environments/hosts environments/playbooks/devicecontroller.yml --tag=init 网络安全设备无需开放外部端口 注意事项consul中应用配置发生变化时需重启相关容器生效。go语言开发，通过gRPC访问。 iotParser服务安装和配置服务说明协议转换服务，支持python，java等多种语言做数据点协议转换。 服务部署应用发布12cd /data/workspace/auto_deploymentansible-playbook -i environments/hosts environments/playbooks/iotparser.yml --tag=init 数据库初始化只需要在应用部署的其中一台主机做一次。123docker-compose -f /data/workspace/iotparser/docker-compose.yml iotparser bashpython manage.py migrate python manage.py migrate createsuperuser 网络安全设备主机无需开放外网入口。 注意事项consul中应用配置发生变化时需重启相关容器生效。 产品元数据服务安装和配置服务说明productmetadata服务用于保存各种产品类型的特征数据，如Lora, Wifi等。 服务部署应用发布12cd /data/workspace/auto_deploymentansible-playbook -i environments/hosts environments/playbooks/productmetadata.yml --tag=init 网络安全设备主机无需开放外网入口。 注意事项consul中应用配置发生变化时需重启相关容器生效。go语言开发，通过gRPC访问。 snoti服务安装和配置服务说明snoti是云对云的数据透传服务，SaaS或第三方平台可通过集成Snoti的SDK连接Snoti服务端，从而达到数据获取和远程控制的能力。Snoti包括4个服务组件：snoti_http: RESTful API服务，用于Snoti帐号管理。snoti_busi: Snoti业务处理服务。snoti_proxy: Snoti长链接代理服务。snoti_xservice: 开发者中心的UI插件。 服务部署数据库初始化只需要在应用部署的其中一台主机做一次。12345use m2m;CREATE TABLE noti_operator ( auth_id varchar(22) NOT NULL, auth_secret varchar(22) NOT NULL, product_key varchar(32) NOT NULL, type varchar(10) NOT NULL, tag text, created_at double DEFAULT NULL, PRIMARY KEY (auth_id), KEY product_key_index (product_key));CREATE TABLE noti_operator_device ( mac varchar(32) NOT NULL, auth_id varchar(22) NOT NULL, did varchar(22) NOT NULL, created_at double DEFAULT NULL, PRIMARY KEY (mac,auth_id)) ;CREATE TABLE noti_operator_permission ( auth_id varchar(32) NOT NULL, code varchar(32) NOT NULL, created_at double DEFAULT NULL, PRIMARY KEY (auth_id,code), KEY auth_id_index (auth_id));CREATE TABLE noti_subkey ( product_key varchar(32) NOT NULL, subkey varchar(32) NOT NULL, auth_id varchar(22) NOT NULL, created_at double DEFAULT NULL, PRIMARY KEY (product_key,subkey), KEY auth_id_index (auth_id)); 应用发布12345cd /data/workspace/auto_deploymentansible-playbook -i environments/hosts environments/playbooks/snoti_http.yml --tag=initansible-playbook -i environments/hosts environments/playbooks/snoti_busi.yml --tag=initansible-playbook -i environments/hosts environments/playbooks/snoti_proxy.yml --tag=initansible-playbook -i environments/hosts environments/playbooks/snoti_xservice.yml --tag=init 网络安全设备内网通过LBS访问，暂无外网入口，主机无需开放任何端口。 注意事项xservice部署时，xservice_id和key需与开发者中心配置一致。 oauth2服务安装和配置服务说明第三方登陆认证服务，存放第三方平台配置与token。 服务部署应用发布12cd /data/workspace/auto_deploymentansible-playbook -i environments/hosts environments/playbooks/oauth2.yml --tag=init 数据库初始化只需要在应用部署的其中一台主机做一次。123docker-compose -f /data/workspace/oauth2/docker-compose.yml shpython manage.py migrate --ignorepython manage.py createsuperuser 网络安全设备外网通过LBS访问，主机无需开放任何端口。 注意事项consul中应用配置发生变化时需重启相关容器生效。 D3引擎服务安装和配置服务说明D3引擎包括规则引擎和消息推送两大部份。其中规则引擎包括8个服务组件：reapi: RESTful API，用于规则管理，也是开发者中心的D3插件。recore: 负责订阅kv数据，交由recore_data处理。recore_data: 根据规则配置处理设备上报的消息数据，得到相关的结果并抛给rabbitmq。notiapi: RESTful API，用于管理消息推送配置，如邮件配置，短信配置，appid与第三方推送平台配置。noti_sms: 当recore_data处理结果满足推送条件时，根据notiapi定义的sms推送方式进行推送。noti_email: 当recore_data处理结果满足推送条件时，根据notiapi定义的email推送方式进行推送。noti_http: 当recore_data处理结果满足推送条件时，根据notiapi定义的http推送方式进行推送。noti_push: 当recore_data处理结果满足推送条件时，根据notiapi定义的push推送方式进行推送。 服务部署应用发布123456789cd /data/workspace/auto_deploymentansible-playbook -i environments/hosts environments/playbooks/d3_reapi.yml --tag=initansible-playbook -i environments/hosts environments/playbooks/d3_recore.yml --tag=initansible-playbook -i environments/hosts environments/playbooks/d3_recore_data.yml --tag=initansible-playbook -i environments/hosts environments/playbooks/d3_notiapi.yml --tag=initansible-playbook -i environments/hosts environments/playbooks/d3_email.yml --tag=initansible-playbook -i environments/hosts environments/playbooks/d3_sms.yml --tag=initansible-playbook -i environments/hosts environments/playbooks/d3_http.yml --tag=initansible-playbook -i environments/hosts environments/playbooks/d3_push.yml --tag=init 数据库初始化只需要在应用部署的其中一台主机做一次。1234567docker-compose -f /data/workspace/d3/reapi/docker-compose.yml exec reapi sh/env-gw_reapi/bin/python manage.py migrate --ignore/env-gw_reapi/bin/python manage.py createsuperuserdocker-compose -f /data/workspace/d3/notiapi/docker-compose.yml exec notiapi sh/env-notification/bin/python manage.py migrate --ignore/env-notification/bin/python manage.py createsuperuser 网络安全设备外网通过LBS访问，主机无需开放任何端口。 注意事项consul中应用配置发生变化时需重启相关容器生效。xservice部署时，xservice_id和key需与开发者中心配置一致。 语音服务安装和配置服务说明语音服务包括四个服务组件，分别为： 服务部署应用发布12345cd /data/workspace/auto_deploymentansible-playbook -i environments/hosts environments/playbooks/voice_converter.yml --tag=initansible-playbook -i environments/hosts environments/playbooks/voice_editor.yml --tag=initansible-playbook -i environments/hosts environments/playbooks/voice_processor.yml --tag=initansible-playbook -i environments/hosts environments/playbooks/voice_subscriber.yml --tag=init 数据库初始化只需要在应用部署的其中一台主机做一次。1234docker-compose -f /data/workspace/voice/editor/docker-compose.yml exec editor shpython manage.py migrate --ignorepython manage.py createsuperuserpython manage.py loaddata config/editor/editor_config.json 网络安全设备外网通过LBS访问，主机无需开放任何端口。 注意事项consul中应用配置发生变化时需重启相关容器生效。语音服务之间请求通过docker网络访问相关服务名称，不通过nginx和LBS转发。 文件备份服务安装和配置服务说明文件备份服务包括raw和kv两种类型的数据文件备份，服务从rabbitmq直接订阅相关数据写到文件中，以event.{pk}.{yyyymmddhh}.json命名，每小时压缩和上传到阿里云OSS。 服务部署应用发布12cd /data/workspace/auto_deploymentansible-playbook -i environments/hosts environments/playbooks/backupfile.yml --tag=init 注意事项服务只能起动一个;部署主机上通过crontab上传压缩文件到阿里云 itest集成测试工具服务说明覆盖m2m、api、ota、snoti等基础功能，跑通过后PaaS核心功能均能通过。 服务部署应用发布12cd /data/workspace/auto_deploymentansible-playbook -i environments/hosts environments/playbooks/itest.yml --tag=init 注意事项服务只能起动一个;测试数据需手动创建。]]></content>
  </entry>
  <entry>
    <title><![CDATA[机智云物联网平台服务等级协议(SLA)]]></title>
    <url>%2FSLA.html</url>
    <content type="text"><![CDATA[为使用机智云向客户提供的机智云物联网平台（简称“物联网平台”），您应当阅读并遵守《机智云物联网平台服务等级协议》（以下简称“本协议”或“SLA”）。本协议包含物联网平台的术语和定义、服务可用性、赔偿方案、免责条款等相关内容。请您务必审慎阅读、充分理解各条款内容，限制、免责条款或者其他涉及您重大权益的条款可能会以加粗、加下划线等形式提示您重点注意。 1. 定义服务周期： 一个服务周期为一个自然月。有效请求： 物联网平台成功接收到客户设备端/APP端/业务云端的所有上行请求，物联网平台成功流转到客户设备端/APP端/业务云端的所有下行请求。失败请求： 因物联网平台系统故障导致的未能成功接收以及流转的有效请求。每5分钟错误率： 以每5分钟为单位按照如下方式计算： 每5分钟错误率=每5分钟失败请求数/每5分钟有效总请求数*100%。服务费用： 客户在一个服务周期内支付给物联网平台的费用。 2. 服务可用性2.1 服务可用性计算方式服务可用性根据服务周期内每5分钟错误率之和除以服务周期内5分钟的总个数计算出每5分钟错误率的平均值，从而计算得出服务可用性，即：服务周期内5分钟总个数 = 12*24*该服务周期的天数服务可用性 =（1-服务周期∑每5分钟错误率/服务周期内5分钟总个数）x 100%。 2.2 服务可用性承诺 ：本平台的服务可用性不低于99.9%，如未达到上述可用性标准（属于免责条款情形的除外），您可以根据本协议第3条约定获得赔偿。 3. 赔偿方案3.1 赔偿标准一般会按服务周期内的可用率分几个等级来划分赔偿方式，需要补充 3.2 赔偿申请时限1) 客户可以在每个自然月第五（5）个工作日后对两个月内没有达到可用性承诺提出赔偿申请。2) 赔偿申请必须限于在物联网平台没有达到可用性的相关月份结束后两（2）个月内提出。3) 超出申请时限的赔偿申请视为客户放弃请求的权利。 3.3 赔偿申请材料如果您认为本服务未达到服务可用性标准的，您可以按照本服务等级协议中规定的时限发起赔偿申请。您的赔偿申请需至少与下列信息一同提供： 服务不用的企业信息、产品信息、问题描述。 服务不可用时长及其他相关证明。 4. 免责条款赔偿范围不包括以下原因所导致的服务不可用： 机智云预先通知客户后进行系统维护所引起的，包括割接、维修、升级和模拟故障演练； 任何机智云所属设备以外的网络、设备故障或配置调整引起的，例如运营商故障、割接等； 客户的应用程序受到黑客攻击而引起的； 客户维护不当或保密不当致使数据、口令、密码等丢失或泄漏所引起的； 客户的疏忽或由客户授权的操作所引起的； 客户未遵循机智云产品使用文档或使用建议引起的，例如设备上报太频繁被限流，不符合规则引擎数据格式而导致数据被丢弃等； 选用MQTT QoS=0的通信机制，但是由于设备不在线导致被丢弃的请求； 由于用户配置错误，或者规则引擎对接的云产品出现异常，而导致写入云产品失败的请求。 属于相关法律法规、相关协议、相关规则或机智云单独发布的相关规则、说明等中所述的机智云可以免责、免除赔偿责任等的情况。 不可抗力引起的。 5. 其他机智云有权对本SLA条款作出修改。如本SLA条款有任何修改，机智云将提前30天以网站公示或发送邮件的方式通知您。如您不同意机智云对SLA所做的修改，您有权停止使用物联网平台，如您继续使用物联网平台，则视为您接受修改后的SLA。]]></content>
  </entry>
  <entry>
    <title><![CDATA[业务云监控指标体系]]></title>
    <url>%2FBizMonitor.html</url>
    <content type="text"><![CDATA[关键词： 安防、多链路、消息推送 监控对象系统指标主机（操作系统）指标，主要指从机器资源角度设定的与机器本身比较相关的指标，主要包括机器的CPU、Memory、Disk IO、Net IO等。 应用指标基础应用指标基础应用指标是指由通用型的应用程序产生的指标，包括： nginxNginx服务器的请求状态、access日志返回码及响应时长分析、服务端口监控。 tomcat redis缓存容量监控、缓存命中率、连接数等 mysql 非基础应用指标非基础应用指标是指业务云开发的服务组件，包括端口、进程数、定时任务启动情况等: app（手机端应用组件） backend（后台应用组件） netty（消息处理应用组件） job（定时任务应用组件） 业务指标接口/业务类 接口/业务并发量，按分钟、小时、天做聚合，支持分时对比。 接口/业务成功量，按分钟、小时、天做聚合，支持分时对比 接口/业务处理时长，按分钟、小时、天做聚合，支持分时对比 消息数据 平台至业务云全链路的每秒消息流量 平台至业务云全链路的每秒消息处理流量 第三方平台接口请求状态 极光/百度app告警推送量与成功率，按分钟、小时、天做聚合。 短信告警推送量与成功率，按分钟、小时、天做聚合。 语音告警推送量与成功率，按分钟、小时、天做聚合。 设备运行情况 在线设备量分时对比。 实时在线设备状态统计占比 设备及在线设备各地域分布状态 业务流程完整度监控 设备配网至联系人配置等各个配置阶段的数据状态监控]]></content>
      <tags>
        <tag>gizwits</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[NGGizwits]]></title>
    <url>%2FNGGizwits.html</url>
    <content type="text"><![CDATA[范围本文主要讲述机智云平台生产环境的部署情况，使得读者可以大概了解每台设备上运行的程序和配置，从而对整个系统的系统软件、应用程序和配置情况有清晰的了解。 术语、定义和缩略语 述语 缩略语 定义 业务中台 b 数据中台 b Tencent Kubernetes Engine TKE 腾讯云基于原生 kubernetes 提供以容器为核心的、高度可扩展的高性能容器管理服务 VPC VPC NET网关 VPC 基础网络 VPC a 总体部署方案设计原则部署要求充分考虑有效资源集中整合、优化的原则，便于日后实现系统的统一规划、应用、管理，从而实现资源的有效共享，在做到集中整合的同时，充分实现高可靠、高可用、高稳定、高性能和易扩展的要求。主要围绕以下目标开展： 异地多活 系统充分解耦 易于运维管理 易于监控管理 易于网络管理 易于日志的统一收集和分析 易于调配的硬件资源，按需分配 系统架构逻辑图 部署说明 全国分为北京、上海、广州等多个区域，不同区域有不同的域名，前端通过智能DNS分发。 不同地域用VPC网络隔离，各VPC之间使用对等网络技术连接。 业务中台规划独立子网，使用腾讯云容器服务（TKE）部署。 数据中心规划独立子网，使用腾讯云的关系型数据库及Redis缓存，但Mongo和RabbitMQ由机智云自行搭建和维护。 数据中心在广州区域，应急容灾中心在上海区域，通过腾讯云DTS服务实时同步。 数据中台规划独立子网，用于大数据智能分析。 运维管理域规划独立子网，用于监控和运维管理。 域名规划 二级域名：gizwits.com 默认域名：m2m.gizwits.com api.gizwits.com enterprise.gizwits.com等 各区域名：在默认域名前加上地区标识，如广州区域为 gzm2m1.gizwits.com gzm2m2.gizwits.com gzapi1.gizwits.com gzapi2.gizwits.com ，上海区域为 shm2m1.gizwits.com shapi1.gizwits.com shm2m1.gizwits.com shapi2.gizwits.com 网络规划VPC与子网 广州： 名称: Gizwits_Prod_GZ CIDR: 10.40.0.0/16 子网: 业务中台 -&gt; 10.40.3.0/24 数据中心 -&gt; 10.40.2.0/24 数据中台 -&gt; 10.40.1.0/24 管理域 -&gt; 10.40.0.0/24 上海： 名称: Gizwits_Prod_SH CIDR: 10.39.0.0/16 子网: 业务中台 -&gt; 10.39.3.0/24 数据中心 -&gt; 10.39.2.0/24 北京： 名称: Gizwits_Prod_BJ CIDR: 10.38.0.0/16 子网: 业务中台 -&gt; 10.38.3.0/24 成都： 名称: Gizwits_Prod_CD CIDR: 10.37.0.0/16 子网: 业务中台 -&gt; 10.37.3.0/24 网络带宽 NAT网关 公网网关 安全组主机规划 类型 配置 数量 标签集 CVM 8核16G 2 role={MANAGEMENT} CVM 8核16G 12 role={BIGDATA} REDIS 8核16G 12 role={RDS} RDS 8核16G 12 role={MYSQL} CVM 8核16G 12 role={MONGO} CVM 8核16G 12 role={RABBITMQ} CVM 8核16G 12 role={M2MST,M2MSB} 应用部署规划 Application Label M2MST0[1-7] role={M2DST0[1-7]} 演进方案VPC迁移基础网络互通可以将基础网络内的云服务器关联至指定私有网络，使基础网络中的云服务器可以访问私有网络内的云服务器、数据库等资源，同时，私有网络内云服务器也可以访问互通的基础网络内云服务器，但无法访问数据库等其他计算资源，在VPC迁移时需按步骤迁移。 数据层迁移至VPC 云主机迁移至VPC数据层云化应用层容器化异地多活部署]]></content>
      <tags>
        <tag>gizwits</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python get weekday]]></title>
    <url>%2Fpython-get-weekday.html</url>
    <content type="text"><![CDATA[Quick Start1234567891011121314import datetimeimport calendardef get_current_week(): monday, sunday = datetime.date.today(), datetime.date.today() one_day = datetime.timedelta(days=1) while monday.weekday() != calendar.MONDAY: monday -= one_day while sunday.weekday() != calendar.SUNDAY: sunday += one_day return monday, sundayprint(get_current_week())]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LC_CTYPE warning]]></title>
    <url>%2FLC-CTYPE-warning.html</url>
    <content type="text"><![CDATA[Quick Startssh登录centos服务器，会显示:1-bash: warning: setlocale: LC_CTYPE: cannot change locale (UTF-8): No such file or directory 解决方案在/etc/environment加入（没有就新建）:12LC_ALL=en_US.UTF-8LANG=en_US.UTF-8]]></content>
      <categories>
        <category>Linux</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[jenkins-plugin installed error]]></title>
    <url>%2Fjenkins-plugin-installed-error.html</url>
    <content type="text"><![CDATA[FaultsThere is an error occurred during initialization of the jenkins:12345OfflineThis Jenkins instance appears to be offline.For information about installing Jenkins without an internet connection, see the Offline Jenkins Installation Documentation. You may choose to continue by configuring a proxy or skipping plugin installation. SolutionIn my case, it has something to do with SSL. I manage to fix it by editing /Users/Shared/Jenkins//Home/hudson.model.UpdateCenter.xml and change url to use “http” instead of “https”.1234567&lt;?xml version=&apos;1.1&apos; encoding=&apos;UTF-8&apos;?&gt;&lt;sites&gt; &lt;site&gt; &lt;id&gt;default&lt;/id&gt; &lt;url&gt;http://updates.jenkins.io/update-center.json&lt;/url&gt; &lt;/site&gt;&lt;/sites&gt; you can also use the available url:https://mirrors.tuna.tsinghua.edu.cn/jenkins/updates/stable-2.7/update-center.json Restart jenkins and reload the website, it no longer shows offline.]]></content>
      <categories>
        <category>jenkins</category>
      </categories>
      <tags>
        <tag>jenkins</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[阿里SLB上使用Webscoket]]></title>
    <url>%2FAliyun-SLB-Websocket.html</url>
    <content type="text"><![CDATA[Quick StartWebsocket是HTML5之后的一个新事物，可以方便的实现客户端到服务端的长会话，特别适合用于客户端需要接收服务端推送的场景。例如在线客服聊天，提醒推送等等。改变了以往客户端只能通过轮询或者long poll来获取服务端状态的限制。 和HTTP协议有什么关系首先我们来看一下Websocket协议和HTTP有什么关系呢？ 本质上说，Websocket和HTTP就不是一个协议，层级不一样。但是为了兼容现有浏览器的握手规范，必须借助HTTP协议建立连接。 这是一个Websocket的握手请求 1234567891011GET wss://server.example.com/ HTTP/1.1Host: server.example.comPragma: no-cacheCache-Control: no-cacheConnection: UpgradeUpgrade: websocketOrigin: https://server.example.comAccept-Encoding: gzip, deflate, brSec-WebSocket-Version: 13Sec-WebSocket-Key: fFFIlFcwULSAmQacRAbS2A==Sec-WebSocket-Extensions: permessage-deflate; client_max_window_bits 这里面有几个和一般HTTP Request不一样的地方， 12345Connection: UpgradeUpgrade: websocketSec-WebSocket-Version: 13Sec-WebSocket-Key: fFFIlFcwULSAmQacRAbS2A==Sec-WebSocket-Extensions: permessage-deflate; client_max_window_bits 这是告诉服务端这不是一个普通的请求，而是Websocket协议。Sec-WebSocket-Key 是一个Base64 encode的值，是浏览器随机生成的，用于让服务端知道这是一个全新的socket客户端。 服务端如果开启了Socket监听，那么就会返回这样的Response12345HTTP/1.1 101 Switching ProtocolsDate: Fri, 09 Mar 2018 16:24:45 GMTConnection: upgradeupgrade: websocketsec-websocket-accept: i/tCy92JmOXIoZwGi8ROh6CgUwk= 表示接收了请求，并且即将切换到Websocket协议，所以code是101。Sec-WebSocket-Accept 这个则是经过服务器确认，并且加密过后的 Sec-WebSocket-Key。到这里HTTP协议的任务就已经完成，之后的通信都是基于Websocket协议了。 怎么通过nginx转发Websocket的握手请求本质上说握手请求就是一个特殊的HTTP Request，只是需要加一些上文提到的特殊内容，从Nignx官方介绍可以看到123456location /wsapp/ &#123; proxy_pass http://wsbackend; proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection &quot;Upgrade&quot;;&#125; 只是在Request header加了两个属性，并且强制升级到HTTP 1.1，原因是HTTP 1.0不支持keep alive。如果使用HTTP 1.0发握手请求，服务端返回101以后就会直接结束这次HTTP会话了。这一点也为之后的坑埋下了伏笔。 坑从何来 自从上线了Websocket服务之后，就会经常发现socket无法建立，获得504的超时响应。12345HTTP/1.1 504 Gateway Time-outDate: Fri, 09 Mar 2018 03:34:54 GMTContent-Type: text/htmlContent-Length: 272Connection: keep-alive 而且这一响应只有在经过SLB（负载均衡）时才有，如果直接请求到我们自己的nginx是没有问题的。但是基于对阿里的信任，还是觉得问题应该还是我们自己这儿。从code review到nginx配置，折腾了五六个小时。 最后只有自己搭建的nginx access log上寻找蛛丝马迹，一开始抓到一些响应都是499的返回，并且request_time时间都在60s上下。1[09/Mar/2018:15:04:51 +0800] 100.97.89.10 - - - 10.0.21.11 to: 10.0.20.11:8011: GET /ws/?id=168451&amp;url=http://server.example.com/ HTTP/1.0 upstream_response_time - msec 1520579091.139 request_time 60.000 status 499 client - Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/64.0.3282.186 Safari/537.36 就考虑是不是socket服务端建立连接后响应不及时，让SLB发现60s没有报文交互直接就切断请求了。 但是因为我们在前端是做了心跳的，即使服务端不响应，只要socket建立通过心跳肯定也会在60s内进行交互。不应该出现上面的场景。 之后我们把access log中socket建立成功的请求和不成功的请求分开放到一起对比，发现不成功的都是HTTP 1.0的协议。 1[09/Mar/2018:15:03:51 +0800] 100.97.88.238 - - - 10.0.20.11 to: 127.0.0.1:8011: GET /ws/?id=168451&amp;url=http://server.example.com HTTP/1.1 upstream_response_time 11.069 msec 1520579031.198 request_time 11.|069 status 101 client - Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/64.0.3282.186 Safari/537.36 |[09/Mar/2018:15:04:32 +0800] 100.97.88.254 - - - 10.0.20.11 to: 127.0.0.1:8011: GET /ws/?id=168451&amp;url=http://server.example.com HTTP/1.0 upstream_response_time - msec 1520579072.716 request_time 36.755 s|tatus 499 client - Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/64.0.3282.186 Safari/537.36 就好像这两个请求，同一个页面发出的，但是一个成功一个失败。失败的正好就是HTTP/1.0，为什么会有两个版本的协议呢， 为了证据更加“确凿”，我们对请求进行了抓包分析，并将Sec-WebSocket-Key打印到Nginx的access log中方便trace同一个请求。123456789GET http://server.example.com/ws/ HTTP/1.1Host: app.linkflowtech.comConnection: UpgradePragma: no-cacheCache-Control: no-cacheUpgrade: websocketOrigin: http://server.example.comSec-WebSocket-Key: 8+qDYeKJGFTWKB2ov4p5TA==Sec-WebSocket-Extensions: permessage-deflate; client_max_window_bits 1[09/Mar/2018:17:07:07 +0800] 100.97.88.252 - - - 10.0.21.11 to: 10.0.20.11:8011: GET /ws/ HTTP/1.0 upstream_response_time - msec 1520586427.537 request_time 59.999 status 499 client - Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/64.0.3282.186 Safari/537.36 8+qDYeKJGFTWKB2ov4p5TA==2018-03-09 17:12:04 可以看到都是 8+qDYeKJGFTWKB2ov4p5TA== 的请求，但是在经过SLB进入nginx时候协议降级到了1.0.这叫一个酸爽，赶紧给阿里云开了工单，经过大概3~4个小时的交流。最终获得一个链接，里面有这样的描述 123在阿里云负载均衡上启用WS/WSS支持无需特殊配置，当选用HTTP监听时，默认支持无加密版本WebSocket协议（WS协议）；当选择HTTPS监听时，默认支持加密版本的WebSocket协议（WSS协议）。注意：需要将实例升级为性能保障型实例。详细参见如何使用负载均衡性能保障型实例 这个大坑就在”注意”那一段，我们的SLB是性能共享型而不是 性能保障型。看来也不是阿里云的问题，是我们的SLB档次不够高啊。知道原因后，立刻付费升级了保障型。实测一下所有问题都解决了。 虽然问题解决了，但是其实很难理解厂商的逻辑，为什么性能共享型中某些SLB节点就会降级HTTP协议版本呢，要知道1.0版本已经是一个相当落后的版本了。]]></content>
      <categories>
        <category>websocket</category>
      </categories>
      <tags>
        <tag>websocket</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Eureka vs Consul vs Zookeeper]]></title>
    <url>%2FEureka-vs-Consul-vs-Zookeeper.html</url>
    <content type="text"><![CDATA[前言在云计算和容器化技术发展火热的当下，对于微服务架构，服务注册与发现组件是必不可少的。在传统的服务架构中，服务的规模处于运维人员的可控范围内。当部署服务的多个节点时，一般使用静态配置的方式实现服务信息的设定。在微服务应用中，服务实例的数量和网络地址都是动态变化的，这对系统运维提出了巨大的挑战。因此，动态的服务注册与发现就显得尤为重要。 解决的问题在一个分布式系统中，服务注册与发现组件主要解决两个问题：服务注册和服务发现。 服务注册： 服务实例将自身服务信息注册到注册中心。这部分服务信息包括服务所在主机IP和提供服务的Port，以及暴露服务自身状态以及访问协议等信息。 服务发现： 服务实例请求注册中心获取所依赖服务信息。服务实例通过注册中心，获取到注册到其中的服务实例的信息，通过这些信息去请求它们提供的服务。 除此之外，服务注册与发现需要关注监控服务实例运行状态、负载均衡等问题。 监控： 微服务应用中，服务处于动态变化的情况，需要一定机制处理无效的服务实例。一般来讲，服务实例与注册中心在注册后通过心跳的方式维系联系，一旦心跳缺少，对应的服务实例会被注册中心剔除。 负载均衡： 同一服务可能同时存在多个实例，需要正确处理对该服务的负载均衡。 CAPCAP原则，指的是在一个分布式系统中，Consistency(一致性)、Availability(可用性)、Partition Tolerance(分区容错性)，不能同时成立。 一致性： 它要求在同一时刻点，分布式系统中的所有数据备份都处于同一状态。 可用性： 在系统集群的一部分节点宕机后，系统依然能够响应用户的请求。 分区容错性： 在网络区间通信出现失败，系统能够容忍。 一般来讲，基于网络的不稳定性，分布容错是不可避免的，所以我们默认CAP中的P总是成立的。 一致性的强制数据统一要求，必然会导致在更新数据时部分节点处于被锁定状态，此时不可对外提供服务，影响了服务的可用性，反之亦然。因此一致性和可用性不能同时满足。 我们接下来介绍的服务注册和发现组件中，Eureka满足了其中的AP，Consul和Zookeeper满足了其中的CP。 EurekaEureka是在Java语言上，基于Restful Api开发的服务注册与发现组件，由Netflix开源。遗憾的是，目前Eureka仅开源到1.X版本，2.X版本已经宣布闭源。 Eureka采用的是Server/Client的模式进行设计。Server扮演了服务注册中心的角色，为Client提供服务注册和发现的功能，维护着注册到自身的Client的相关信息，同时提供接口给Client获取到注册表中其他服务的信息。Client将有关自己的服务的信息通过一定的方式登记到Server上，并在正常范围内维护自己信息的一致性，方便其他服务发现自己，同时可以通过Server获取到自己的依赖的其他服务信息，从而完成服务调用。 它的架构图如下所示： Application Service： 作为Eureka Client，扮演了服务的提供者，提供业务服务，向Eureka Server注册和更新自己的信息，同时能从Eureka Server的注册表中获取到其他服务的信息。 Eureka Server： 扮演服务注册中心的角色，提供服务注册和发现的功能，每个Eureka Cient向Eureka Server注册自己的信息，也可以通过Eureka Server获取到其他服务的信息达到发现和调用其他服务的目的。 Application Client： 作为Eureka Client，扮演了服务消费者，通过Eureka Server获取到注册到上面的其他服务的信息，从而根据信息找到所需的服务发起远程调用。 Replicate： Eureka Server中的注册表信息的同步拷贝，保持不同的Eureka Server集群中的注册表中的服务实例信息的一致性。提供了数据的最终一致性。 Make Remote Call： 服务之间的远程调用。 Register： 注册服务实例，Client端向Server端注册自身的元数据以进行服务发现。 Renew： 续约，通过发送心跳到Server维持和更新注册表中的服务实例元数据的有效性。当在一定时长内Server没有收到Client的心跳信息，将默认服务下线，将服务实例的信息从注册表中删除。 Cancel： 服务下线，Client在关闭时主动向Server注销服务实例元数据，这时Client的的服务实例数据将从Server的注册表中删除。 Eureka中没有使用任何的数据强一致性算法保证不同集群间的Server的数据一致，仅通过数据拷贝的方式争取注册中心数据的最终一致性，虽然放弃数据强一致性但是换来了Server的可用性，降低了注册的代价，提高了集群运行的健壮性。 ConsulConsul是由HashiCorp基于Go语言开发的支持多数据中心分布式高可用的服务发布和注册服务软件，采用Raft算法保证服务的一致性，且支持健康检查。 Consul采用主从模式的设计，使得集群的数量可以大规模扩展，集群间通过RPC的方式调用(HTTP和DNS)。它的结构图如下所示： Client： 作为一个代理(非微服务实例)，它将转发所有的RPC请求到Server中。作为相对无状态的服务，它不持有任何注册信息。 Server： 作为一个具备扩展功能的代理，它将响应RPC查询、参与Raft选举、维护集群状态和转发查询给Leader等。 Leader-Server： 一个数据中心的所有Server都作为Raft节点集合的一部分。其中Leader将负责所有的查询和事务(如服务注册)，同时这些事务也会被复制到所有其他的节点。 Data Center： 数据中心作为一个私有的，低延迟和高带宽的一个网络环境。每个数据中心会存在Consul集群，一般建议Server是3-5台(考虑到Raft算法在可用性和性能上取舍)，而Leader只能唯一，Client的数量没有限制，可以轻松扩展。 Raft算法Raft算法将Server分为三种类型：Leader、Follower和Candidate。Leader处理所有的查询和事务，并向Follower同步事务。Follower会将所有的RPC查询和事务转发给Leader处理，它仅从Leader接受事务的同步。数据的一致性以Leader中的数据为准实现。 在节点初始启动时，节点的Raft状态机将处于Follower状态等待来来自Leader节点的心跳。如果在一定时间周期内没有收到Leader节点的心跳，节点将发起选举。 Follower节点选举时会将自己的状态切换为Candidate，然后向集群中其它Follower节点发送请求，询问其是否选举自己成为Leader。当收到来自集群中过半数节点的接受投票后，节点即成为Leader，开始接收Client的事务处理和查询并向其它的Follower节点同步事务。Leader节点会定时向Follower发送心跳来保持其地位。 Gossip协议Gossip协议是为了解决分布式环境下监控和事件通知的瓶颈。Gossip协议中的每个Agent会利用Gossip协议互相检查在线状态，分担了服务器节点的心跳压力，通过Gossip广播的方式发送消息。 所有的Agent都运行着Gossip协议。服务器节点和普通Agent都会加入这个Gossip集群，收发Gossip消息。每隔一段时间，每个节点都会随机选择几个节点发送Gossip消息，其他节点会再次随机选择其他几个节点接力发送消息。这样一段时间过后，整个集群都能收到这条消息。 基于Raft算法，Consul提供强一致性的注册中心服务，但是由于Leader节点承担了所有的处理工作，势必加大了注册和发现的代价，降低了服务的可用性。通过Gossip协议，Consul可以很好地监控Consul集群的运行，同时可以方便通知各类事件，如Leader选择发生、Server地址变更等。 ZookeeperZookeeper是由Google开源的在Java语言上实现的分布式协调服务，是Hadoop和Hbase的重要组件，提供了数据/发布订阅、负载均衡、分布式同步等功能。 Zookeeper也是基于主从架构，搭建了一个可高扩展的服务集群，其服务架构如下： Leader-Server： Leader负责进行投票的发起和决议，更新系统中的数据状态 Server： Server中存在两种类型：Follower和Observer。其中Follower接受客户端的请求并返回结果(事务请求将转发给Leader处理)，并在选举过程中参与投票；Observer与Follower功能一致，但是不参与投票过程，它的存在是为了提高系统的读取速度 Client： 请求发起方，Server和Client之间可以通过长连接的方式进行交互。如发起注册或者请求集群信息等。 Zab协议ZooKeeper Atomic Broadcast protocol是专门设计给Zookeeper用于实现分布式系统数据的一致性，是在Paxos算法基础上发展而来。它使用了单一的Leader来接受和处理客户端的所有事务请求，并将服务器数据的状态变更以事务Proposal的形式广播到所有的Server中。同时它保证Leader出现异常时，集群依旧能够正常工作。Zab包含两种基本模式：崩溃恢复和消息广播。 崩溃恢复： Leader服务器出现宕机，或者因为网络原因导致Leader服务器失去了与过半 Follower的联系，那么就会进入崩溃恢复模式从而选举新的Leader。Leader选举算法不仅仅需要让Leader自己知道其自身已经被选举为Leader，同时还需要让集群中的所有其他服务器也能够快速地感知到选举产生的新的Leader。当选举产生了新的Leader，同时集群中有过半的服务器与该Leader完成了状态同步之后，Zab协议就会退出崩溃恢复模式，进入消息广播模式。 消息广播： Zab协议的消息广播过程类似二阶段提供过程，是一种原子广播的协议。当接受到来自Client的事务请求(如服务注册)(所有的事务请求都会转发给Leader)，Leader会为事务生成对应的Proposal，并为其分配一个全局唯一的ZXID。Leader服务器与每个Follower之间都有一个单独的队列进行收发消息，Leader将生成的Proposal发送到队列中。Follower从队列中取出Proposal进行事务消费，消费完毕后发送一个ACK给Leader。当Leader接受到半数以上的Follower发送的ACK投票，它将发送Commit给所有Follower通知其对事务进行提交，Leader本身也会提交事务，并返回给处理成功给对应的客户端。Follower只有将队列中Proposal都同步消费后才可用。 基于Zab协议，Zookeeper可以用于构建具备数据强一致性的服务注册与发现中心，而与此相对地牺牲了服务的可用性和提高了注册需要的时间。 异同点最后我们通过一张表格大致了解Eureka、Consul、Zookeeper的异同点。选择什么类型的服务注册与发现组件可以根据自身项目要求决定。 链接：https://www.jianshu.com/p/086f8066188b]]></content>
      <categories>
        <category>服务发现</category>
      </categories>
      <tags>
        <tag>服务发现</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MQTT协议简介]]></title>
    <url>%2FMQTT-Protocol.html</url>
    <content type="text"><![CDATA[概述MQTT（Message Queuing Telemetry Transport，消息队列遥测传输协议），是一种基于发布/订阅（publish/subscribe）模式的“轻量级”通讯协议，该协议构建于TCP/IP协议上，由IBM在1999年发布。MQTT最大优点在于，可以以极少的代码和有限的带宽，为连接远程设备提供实时可靠的消息服务。作为一种低开销、低带宽占用的即时通讯协议，使其在物联网、小型设备、移动应用等方面有较广泛的应用。MQTT是一个基于客户端-服务器的消息发布/订阅传输协议。MQTT协议是轻量、简单、开放和易于实现的，这些特点使它适用范围非常广泛。在很多情况下，包括受限的环境中，如：机器与机器（M2M）通信和物联网（IoT）。其在通过卫星链路通信传感器、偶尔拨号的医疗设备、智能家居、及一些小型化设备中已广泛使用。建议在MQTT官网获取当前MQTT协议的最新版本。除标准版外，还有一个简化版MQTT-SN，该协议主要针对嵌入式设备，这些设备一般工作于TCP/IP网络，如：ZigBee。 设计原则由于物联网的环境是非常特别的，所以MQTT遵循以下设计原则： 精简，不添加可有可无的功能； 发布/订阅（Pub/Sub）模式，方便消息在传感器之间传递； 允许用户动态创建主题，零运维成本； 把传输量降到最低以提高传输效率； 把低带宽、高延迟、不稳定的网络等因素考虑在内； 支持连续的会话控制； 理解客户端计算能力可能很低； 提供服务质量管理； 假设数据不可知，不强求传输数据的类型与格式，保持灵活性。 特性MQTT协议工作在低带宽、不可靠的网络的远程传感器和控制设备通讯而设计的协议，它具有以下主要的几项特性： 使用发布/订阅消息模式，提供一对多的消息发布，解除应用程序耦合。这一点很类似于XMPP，但是MQTT的信息冗余远小于XMPP，因为XMPP使用XML格式文本来传递数据。 对负载内容屏蔽的消息传输。 使用TCP/IP提供网络连接。 有三种消息发布服务质量：至多一次: 消息发布完全依赖底层TCP/IP网络。会发生消息丢失或重复。这一级别可用于如下情况，环境传感器数据，丢失一次读记录无所谓，因为不久后还会有第二次发送。这一种方式主要普通APP的推送，倘若你的智能设备在消息推送时未联网，推送过去没收到，再次联网也就收不到了。至少一次: 确保消息到达，但消息重复可能会发生。只有一次: 确保消息到达一次。在一些要求比较严格的计费系统中，可以使用此级别。在计费系统中，消息重复或丢失会导致不正确的结果。这种最高质量的消息发布服务还可以用于即时通讯类的APP的推送，确保用户收到且只会收到一次。 小型传输，开销很小（固定长度的头部是2字节），协议交换最小化，以降低网络流量。这就是为什么在介绍里说它非常适合“在物联网领域，传感器与服务器的通信，信息的收集”，要知道嵌入式设备的运算能力和带宽都相对薄弱，使用这种协议来传递消息再适合不过了。 使用Last Will和Testament特性通知有关各方客户端异常中断的机制。Last Will：即遗言机制，用于通知同一主题下的其他设备发送遗言的设备已经断开了连接。Testament：遗嘱机制，功能类似于Last Will。 MQTT协议原理MQTT协议实现方式实现MQTT协议需要客户端和服务器端通讯完成，在通讯过程中，MQTT协议中有三种身份：发布者（Publish）、代理（Broker）/（服务器）、订阅者（Subscribe）。其中，消息的发布者和订阅者都是客户端，消息代理是服务器，消息发布者可以同时是订阅者。MQTT传输的消息分为：主题（Topic）和负载（payload）两部分： topic: 可以理解为消息的类型，订阅者订阅（Subscribe）后，就会收到该主题的消息内容（payload）； payload: 可以理解为消息的内容，是指订阅者具体要使用的内容。 网络传输与应用消息MQTT会构建底层网络传输：它将建立客户端到服务器的连接，提供两者之间的一个有序的、无损的、基于字节流的双向传输。当应用数据通过MQTT网络发送时，MQTT会把与之相关的服务质量（QoS）和主题名（Topic）相关连。 MQTT客户端一个使用MQTT协议的应用程序或者设备，它总是建立到服务器的网络连接。客户端可以： 发布其他客户端可能会订阅的信息； 订阅其它客户端发布的消息； 退订或删除应用程序的消息； 断开与服务器连接。 MQTT服务器MQTT服务器以称为“消息代理”（Broker），可以是一个应用程序或一台设备。它是位于消息发布者和订阅者之间，它可以： 接受来自客户的网络连接； 接受客户发布的应用信息； 处理来自客户端的订阅和退订请求； 向订阅的客户转发应用程序消息。 MQTT协议中的订阅、主题、会话订阅（Subscription）订阅包含主题筛选器（Topic Filter）和最大服务质量（QoS）。订阅会与一个会话（Session）关联。一个会话可以包含多个订阅。每一个会话中的每个订阅都有一个不同的主题筛选器。 会话（Session）每个客户端与服务器建立连接后就是一个会话，客户端和服务器之间有状态交互。会话存在于一个网络之间，也可能在客户端和服务器之间跨越多个连续的网络连接。 主题名（Topic Name）连接到一个应用程序消息的标签，该标签与服务器的订阅相匹配。服务器会将消息发送给订阅所匹配标签的每个客户端。 主题筛选器（Topic Filter）一个对主题名通配符筛选器，在订阅表达式中使用，表示订阅所匹配到的多个主题。 负载（Payload）消息订阅者所具体接收的内容。 MQTT协议中的方法MQTT协议中定义了一些方法（也被称为动作），来于表示对确定资源所进行操作。这个资源可以代表预先存在的数据或动态生成数据，这取决于服务器的实现。通常来说，资源指服务器上的文件或输出。主要方法有： Connect: 等待与服务器建立连接。 Disconnect: 等待MQTT客户端完成所做的工作，并与服务器断开TCP/IP会话。 Subscribe: 等待完成订阅。 UnSubscribe: 等待服务器取消客户端的一个或多个topics订阅。 Publish: MQTT客户端发送消息请求，发送完成后返回应用程序线程。 MQTT协议数据包结构在MQTT协议中，一个MQTT数据包由：固定头（Fixed header）、可变头（Variable header）、消息体（payload）三部分构成。MQTT数据包结构如下： 固定头（Fixed header）: 存在于所有MQTT数据包中，表示数据包类型及数据包的分组类标识。 可变头（Variable header）: 存在于部分MQTT数据包中，数据包类型决定了可变头是否存在及其具体内容。 消息体（Payload）: 存在于部分MQTT数据包中，表示客户端收到的具体内容。 MQTT固定头固定头存在于所有MQTT数据包中，其结构如下： MQTT数据包类型位置：Byte 1中bits 7-4。相于一个4位的无符号值，类型、取值及描述如下： 标识位位置：Byte 1中bits 3-0。在不使用标识位的消息类型中，标识位被作为保留位。如果收到无效的标志时，接收端必须关闭网络连接： DUP：发布消息的副本。用来在保证消息的可靠传输，如果设置为1，则在下面的变长中增加MessageId，并且需要回复确认，以保证消息传输完成，但不能用于检测消息重复发送。 QoS：发布消息的服务质量，即：保证消息传递的次数 1234Ø00：最多一次，即：&lt;=1Ø01：至少一次，即：&gt;=1Ø10：一次，即：=1Ø11：预留 RETAIN： 发布保留标识，表示服务器要保留这次推送的信息，如果有新的订阅者出现，就把这消息推送给它，如果设有那么推送至当前订阅者后释放。 剩余长度（Remaining Length）地址：Byte 2。固定头的第二字节用来保存变长头部和消息体的总大小的，但不是直接保存的。这一字节是可以扩展，其保存机制，前7位用于保存长度，后一部用做标识。当最后一位为1时，表示长度不足，需要使用二个字节继续保存。例如：计算出后面的大小为0 MQTT可变头MQTT数据包中包含一个可变头，它驻位于固定的头和负载之间。可变头的内容因数据包类型而不同，较常的应用是作为包的标识：很多类型数据包中都包括一个2字节的数据包标识字段，这些类型的包有：PUBLISH (QoS &gt; 0)、PUBACK、PUBREC、PUBREL、PUBCOMP、SUBSCRIBE、SUBACK、UNSUBSCRIBE、UNSUBACK。 Payload消息体Payload消息体位MQTT数据包的第三部分，包含CONNECT、SUBSCRIBE、SUBACK、UNSUBSCRIBE四种类型的消息： CONNECT: 消息体内容主要是：客户端的ClientID、订阅的Topic、Message以及用户名和密码。 SUBSCRIBE: 消息体内容是一系列的要订阅的主题以及QoS。 SUBACK: 消息体内容是服务器对于SUBSCRIBE所申请的主题及QoS进行确认和回复。 UNSUBSCRIBE: 消息体内容是要订阅的主题。 原文：https://www.jianshu.com/p/5c42cb0ed1e9]]></content>
      <categories>
        <category>mqtt</category>
      </categories>
      <tags>
        <tag>mqtt</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mongodb架构模式、持久化原理和数据文件存储原理]]></title>
    <url>%2Fcore-principles-of-mongodb.html</url>
    <content type="text"><![CDATA[概述MongoDB 是一个基于分布式文件存储的数据库。由 C++ 语言编写。旨在为 WEB 应用提供可扩展的高性能数据存储解决方案。MongoDB 是一个介于关系数据库和非关系数据库之间的产品，是非关系数据库当中功能最丰富，最像关系数据库的。以下mongodb的持久化原理、架构模式和数据文件存储原理。 架构模式Replica set：复制集，mongodb的架构方式之一 ，通常是三个对等的节点构成一个“复制集”集群，有“primary”和secondary等多中角色（稍后详细介绍），其中primary负责读写请求，secondary可以负责读请求，这有配置决定，其中secondary紧跟primary并应用write操作；如果primay失效，则集群进行“多数派”选举，选举出新的primary，即failover机制，即HA架构。复制集解决了单点故障问题，也是mongodb垂直扩展的最小部署单位，当然sharding cluster中每个shard节点也可以使用Replica set提高数据可用性。 Sharding cluster：分片集群，数据水平扩展的手段之一；replica set这种架构的缺点就是“集群数据容量”受限于单个节点的磁盘大小，如果数据量不断增加，对它进行扩容将时非常苦难的事情，所以我们需要采用Sharding模式来解决这个问题。将整个collection的数据将根据sharding key被sharding到多个mongod节点上，即每个节点持有collection的一部分数据，这个集群持有全部数据，原则上sharding可以支撑数TB的数据。 系统配置： 建议mongodb部署在linux系统上，较高版本，选择合适的底层文件系统（ext4），开启合适的swap空间 无论是MMAPV1或者wiredTiger引擎，较大的内存总能带来直接收益。 对数据存储文件关闭“atime”（文件每次access都会更改这个时间值，表示文件最近被访问的时间），可以提升文件访问效率。 ulimit参数调整，这个在基于网络IO或者磁盘IO操作的应用中，通常都会调整，上调系统允许打开的文件个数（ulimit -n 65535）。 持久化原理持久化为了保证数据永久保存不丢失。MongoDB具有高度可配置的持久化设置，从完全没有任何保证到完全持久化。mongodb与mysql不同，mysql的每一次更新操作都会直接写入硬盘，但是mongo不会，做为内存型数据库，数据操作会先写入内存，然后再会持久化到硬盘中去。在mongodb在启动时，专门初始化一个线程不断循环（除非应用crash掉），用于在一定时间周期内来从defer队列中获取要持久化的数据并写入到磁盘的journal(日志)和mongofile(数据)处，因为它不是在用户添加记录时就写到磁盘上，所以按mongodb开发者说，它不会造成性能上的损耗，因为看过代码发现，当进行CUD操作时，记录(Record类型)都被放入到defer队列中以供延时批量（groupcommit）提交写入，但相信其中时间周期参数是个要认真考量的参数，系统为90毫秒，如果该值更低的话，可能会造成频繁磁盘操作，过高又会造成系统宕机时数据丢失过。 数据文件存储原理（Data Files storage，MMAPV1引擎）Data Filesmongodb的数据将会保存在底层文件系统中，比如我们dbpath设定为“/data/db”目录，我们创建一个database为“test”，collection为“sample”，然后在此collection中插入数条documents。我们查看dbpath下生成的文件列表 可以看到test这个数据库目前已经有6个数据文件（data files），每个文件以“database”的名字 + 序列数字组成，序列号从0开始，逐个递增，数据文件从16M开始，每次扩张一倍（16M、32M、64M、128M…），在默认情况下单个data file的最大尺寸为2G，如果设置了smallFiles属性（配置文件中）则最大限定为512M；mongodb中每个database最多支持16000个数据文件，即约32T，如果设置了smallFiles则单个database的最大数据量为8T。 Namespace文件对于namespace文件，比如“test.ns”文件，默认大小为16M，此文件中主要用于保存“collection”、index的命名信息，比如collection的“属性”信息、每个索引的属性类型等，如果你的database中需要存储大量的collection（比如每一小时生成一个collection，在数据分析应用中），那么我们可以通过配置文件“nsSize”选项来指定 journal文件journal日志为mongodb提供了数据保障能力，它本质上与mysql binlog没有太大区别，用于当mongodb异常crash后，重启时进行数据恢复；这归结于mongodb的数据持久写入磁盘是滞后的。默认情况下，“journal”特性是开启的，特别在production环境中，我们没有理由来关闭它。（除非，数据丢失对应用而言，是无关紧要的） 一个mongodb实例中所有的databases共享journal文件。对于write操作而言，首先写入journal日志，然后将数据在内存中修改（mmap），此后后台线程间歇性的将内存中变更的数据flush到底层的data files中，时间间隔为60秒（参见配置项“syncPeriodSecs”）；write操作在journal文件中是有序的，为了提升性能，write将会首先写入journal日志的内存buffer中，当buffer数据达到100M或者每隔100毫秒，buffer中的数据将会flush到磁盘中的journal文件中；如果mongodb异常退出，将可能导致最多100M数据或者最近100ms内的数据丢失，flush磁盘的时间间隔有配置项“commitIntervalMs”决定，默认为100毫秒。mongodb之所以不能对每个write都将journal同步磁盘，这也是对性能的考虑，mysql的binlog也采用了类似的权衡方式。开启journal日志功能，将会导致write性能有所降低，可能降低5~30%，因为它直接加剧了磁盘的写入负载，我们可以将journal日志单独放置在其他磁盘驱动器中来提高写入并发能力（与data files分别使用不同的磁盘驱动器）。 如果你希望数据尽可能的不丢失，可以考虑： 减小commitIntervalMs的值 每个write指定“write concern”中指定“j”参数为true 最佳手段就是采用“replica set”架构模式，通过数据备份方式解决，同时还需要在“write concern”中指定“w”选项，且保障级别不低于“majority”。]]></content>
      <categories>
        <category>mongodb</category>
      </categories>
      <tags>
        <tag>mongodb</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[消息队列基础知识]]></title>
    <url>%2FBasic-Of-MQ.html</url>
    <content type="text"><![CDATA[Quick Start消息队列之常用协议AMQP AMQP即Advanced Message Queuing Protocol,一个提供统一消息服务的应用层标准高级消息队列协议, 是应用层协议的一个开放标准,为面向消息的中间件设计。基于此协议的客户端与消息中间件可传递消息，并 不受客户端/中间件不同产品，不同开发语言等条件的限制。 优点：可靠、通用 MQTT MQTT（Message Queuing Telemetry Transport，消息队列遥测传输）是IBM开发的一个即时通讯协 议，有可能成为物联网的重要组成部分。该协议支持所有平台，几乎可以把所有联网物品和外部连接起来， 被用来当做传感器和致动器（比如通过Twitter让房屋联网）的通信协议。 优点：格式简洁、占用带宽小、移动端通信、PUSH、嵌入式系统 STOMP协议 STOMP（Streaming Text Orientated Message Protocol）是流文本定向消息协议，是一种为MOM(Message Oriented Middleware，面向消息的中间件设计的简单文本协议。STOMP提供一个可互操作的连接格式，允许客户端与任意STOMP消息代理（Broker）进行交互。 优点：命令模式（非topicqueue模式） XMPP协议 XMPP（可扩展消息处理现场协议，Extensible Messaging and Presence Protocol）是基于可扩展标记语言（XML）的协议，多用于即时消息（IM）以及在线现场探测。适用于服务器之间的准即时操作。核心是基于XML流传输，这个协议可能最终允许因特网用户向因特网上的其他任何人发送即时消息，即使其操作系统和浏览器不同。 优点：通用公开、兼容性强、可扩展、安全性高，但XML编码格式占用带宽大 其他基于TCP/IP自定义的协议 有些特殊框架（如：redis、kafka、zeroMq等）根据自身需要未严格遵循MQ规范，而是基于TCPIP自行封装了一套协议，通过网络socket接口进行传输，实现了MQ的功能。 消息队列之模型 Pub/Sub发布订阅（广播）：使用topic作为通信载体 PTP点对点:使用queue作为通信载体 消息队列的组成模块 Broker：消息服务器，作为server提供消息核心服务 Producer:消息生产者，业务的发起方，负责生产消息传输给broker Consumer：消息消费者，业务的处理方，负责从broker获取消息并进行业务逻辑处理 Topic:主题，发布订阅模式下的消息统一汇集地，不同生产者向topic发送消息，由MQ服务器分发到不同的订阅者，实现消息的广播 Queue：队列，PTP模式下，特定生产者向特定queue发送消息，消费者订阅特定的queue完成指定消息的接收 Message：消息体，根据不同通信协议定义的固定格式进行编码的数据包，来封装业务数据，实现消息的传输]]></content>
      <categories>
        <category>MQ</category>
      </categories>
      <tags>
        <tag>MQ</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[常用消息队列对比]]></title>
    <url>%2FCommon-MQ-Comparison.html</url>
    <content type="text"><![CDATA[Quick Start本部分主要介绍四种常用的消息队列（RabbitMQ/ActiveMQ/RocketMQ/Kafka）的主要特性、优点、缺点。 RabbitMQRabbitMQ 2007年发布，是一个在AMQP(高级消息队列协议)基础上完成的，可复用的企业消息系统，是当前最主流的消息中间件之一。主要特性： 可靠性: 提供了多种技术可以让你在性能和可靠性之间进行权衡。这些技术包括持久性机制、投递确认、发布者证实和高可用性机制； 灵活的路由： 消息在到达队列前是通过交换机进行路由的。RabbitMQ为典型的路由逻辑提供了多种内置交换机类型。如果你有更复杂的路由需求，可以将这些交换机组合起来使用，你甚至可以实现自己的交换机类型，并且当做RabbitMQ的插件来使用； 消息集群：在相同局域网中的多个RabbitMQ服务器可以聚合在一起，作为一个独立的逻辑代理来使用； 队列高可用：队列可以在集群中的机器上进行镜像，以确保在硬件问题下还保证消息安全； 多种协议的支持：支持多种消息队列协议； 服务器端用Erlang语言编写，支持只要是你能想到的所有编程语言； 管理界面: RabbitMQ有一个易用的用户界面，使得用户可以监控和管理消息Broker的许多方面； 跟踪机制：如果消息异常，RabbitMQ提供消息跟踪机制，使用者可以找出发生了什么； 插件机制：提供了许多插件，来从多方面进行扩展，也可以编写自己的插件； 使用RabbitMQ需要：12ErLang语言包RabbitMQ安装包 RabbitMQ可以运行在Erlang语言所支持的平台之上：123456789SolarisBSDLinuxMacOSXTRU64Windows NT/2000/XP/Vista/Windows 7/Windows 8Windows Server 2003/2008/2012Windows 95, 98VxWorks 优点： 由于erlang语言的特性，mq 性能较好，高并发； 健壮、稳定、易用、跨平台、支持多种语言、文档齐全； 有消息确认机制和持久化机制，可靠性高； 高度可定制的路由； 管理界面较丰富，在互联网公司也有较大规模的应用； 社区活跃度高； 缺点： 尽管结合erlang语言本身的并发优势，性能较好，但是不利于做二次开发和维护； 实现了代理架构，意味着消息在发送到客户端之前可以在中央节点上排队。此特性使得RabbitMQ易于使用和部署，但是使得其运行速度较慢，因为中央节点增加了延迟，消息封装后也比较大； 需要学习比较复杂的接口和协议，学习和维护成本较高； ActiveMQActiveMQ是由Apache出品，ActiveMQ 是一个完全支持JMS1.1和J2EE 1.4规范的 JMS Provider实现。它非常快速，支持多种语言的客户端和协议，而且可以非常容易的嵌入到企业的应用环境中，并有许多高级功能。 主要特性： 服从 JMS 规范：JMS 规范提供了良好的标准和保证，包括：同步或异步的消息分发，一次和仅一次的消息分发，消息接收和订阅等等。遵从 JMS 规范的好处在于，不论使用什么 JMS 实现提供者，这些基础特性都是可用的； 连接性：ActiveMQ 提供了广泛的连接选项，支持的协议有：HTTP/S，IP 多播，SSL，STOMP，TCP，UDP，XMPP等等。对众多协议的支持让 ActiveMQ 拥有了很好的灵活性。 支持的协议种类多：OpenWire、STOMP、REST、XMPP、AMQP ； 持久化插件和安全插件：ActiveMQ 提供了多种持久化选择。而且，ActiveMQ 的安全性也可以完全依据用户需求进行自定义鉴权和授权； 支持的客户端语言种类多：除了 Java 之外，还有：C/C++，.NET，Perl，PHP，Python，Ruby； 代理集群：多个 ActiveMQ 代理可以组成一个集群来提供服务； 异常简单的管理：ActiveMQ 是以开发者思维被设计的。所以，它并不需要专门的管理员，因为它提供了简单又使用的管理特性。有很多中方法可以监控 ActiveMQ 不同层面的数据，包括使用在 JConsole 或者 ActiveMQ 的Web Console 中使用 JMX，通过处理 JMX 的告警消息，通过使用命令行脚本，甚至可以通过监控各种类型的日志。 使用ActiveMQ需要：123Java JDKActiveMQ安装包ActiveMQ可以运行在Java语言所支持的平台之上。 优点： 跨平台(JAVA编写与平台无关有，ActiveMQ几乎可以运行在任何的JVM上) 可以用JDBC：可以将数据持久化到数据库。虽然使用JDBC会降低ActiveMQ的性能，但是数据库一直都是开发人员最熟悉的存储介质。将消息存到数据库，看得见摸得着。而且公司有专门的DBA去对数据库进行调优，主从分离； 支持JMS ：支持JMS的统一接口; 支持自动重连； 有安全机制：支持基于shiro，jaas等多种安全配置机制，可以对Queue/Topic进行认证和授权。 监控完善：拥有完善的监控，包括Web Console，JMX，Shell命令行，Jolokia的REST API； 界面友善：提供的Web Console可以满足大部分情况，还有很多第三方的组件可以使用，如hawtio； 缺点： 社区活跃度不及RabbitMQ高； 根据其他用户反馈，会出莫名其妙的问题，会丢失消息； 目前重心放到activemq6.0产品-apollo，对5.x的维护较少； 不适合用于上千个队列的应用场景； RocketMQRocketMQ出自 阿里公司的开源产品，用 Java 语言实现，在设计时参考了 Kafka，并做出了自己的一些改进，消息可靠性上比 Kafka 更好。RocketMQ在阿里集团被广泛应用在订单，交易，充值，流计算，消息推送，日志流式处理，binglog分发等场景。 主要特性： 是一个队列模型的消息中间件，具有高性能、高可靠、高实时、分布式特点； Producer、Consumer、队列都可以分布式； Producer向一些队列轮流发送消息，队列集合称为Topic，Consumer如果做广播消费，则一个consumer实例消费这个Topic对应的所有队列，如果做集群消费，则多个Consumer实例平均消费这个topic对应的队列集合； 能够保证严格的消息顺序； 提供丰富的消息拉取模式； 高效的订阅者水平扩展能力； 实时的消息订阅机制； 亿级消息堆积能力； 较少的依赖； 使用RocketMQ需要：1234Java JDK安装git、MavenRocketMQ安装包RocketMQ可以运行在Java语言所支持的平台之上。 优点： 单机支持 1 万以上持久化队列 RocketMQ 的所有消息都是持久化的，先写入系统 PAGECACHE，然后刷盘，可以保证内存与磁盘都有一份数据， 访问时，直接从内存读取。 模型简单，接口易用（JMS 的接口很多场合并不太实用）； 性能非常好，可以大量堆积消息在broker中； 支持多种消费，包括集群消费、广播消费等。 各个环节分布式扩展设计，主从HA； 开发度较活跃，版本更新很快。 缺点： 支持的客户端语言不多，目前是java及c++，其中c++不成熟； RocketMQ社区关注度及成熟度也不及前两者； 没有web管理界面，提供了一个CLI(命令行界面)管理工具带来查询、管理和诊断各种问题； 没有在 mq 核心中去实现JMS等接口； KafkaApache Kafka是一个分布式消息发布订阅系统。它最初由LinkedIn公司基于独特的设计实现为一个分布式的提交日志系统( a distributed commit log)，，之后成为Apache项目的一部分。Kafka系统快速、可扩展并且可持久化。它的分区特性，可复制和可容错都是其不错的特性。 主要特性： 快速持久化，可以在O(1)的系统开销下进行消息持久化； 高吞吐，在一台普通的服务器上既可以达到10W/s的吞吐速率； 完全的分布式系统，Broker、Producer、Consumer都原生自动支持分布式，自动实现负载均衡； 支持同步和异步复制两种HA； 支持数据批量发送和拉取； zero-copy：减少IO操作步骤； 数据迁移、扩容对用户透明； 无需停机即可扩展机器； 其他特性：严格的消息顺序、丰富的消息拉取模型、高效订阅者水平扩展、实时的消息订阅、亿级的消息堆积能力、定期删除机制； 使用Kafka需要：12Java JDKKafka安装包 优点： 客户端语言丰富，支持java、.net、php、ruby、python、go等多种语言； 性能卓越，单机写入TPS约在百万条/秒，消息大小10个字节； 提供完全分布式架构, 并有replica机制, 拥有较高的可用性和可靠性, 理论上支持消息无限堆积； 支持批量操作； 消费者采用Pull方式获取消息, 消息有序, 通过控制能够保证所有消息被消费且仅被消费一次; 有优秀的第三方Kafka Web管理界面Kafka-Manager； 在日志领域比较成熟，被多家公司和多个开源项目使用； 缺点： Kafka单机超过64个队列/分区，Load会发生明显的飙高现象，队列越多，load越高，发送消息响应时间变长 使用短轮询方式，实时性取决于轮询间隔时间； 消费失败不支持重试； 支持消息顺序，但是一台代理宕机后，就会产生消息乱序； 社区更新较慢； 消息队列对比 结论Kafka在于分布式架构，RabbitMQ基于AMQP协议来实现，RocketMQ/思路来源于kafka，改成了主从结构，在事务性可靠性方面做了优化。广泛来说，电商、金融等对事务性要求很高的，可以考虑RabbitMQ和RocketMQ，对性能要求高的可考虑Kafka。]]></content>
      <categories>
        <category>MQ</category>
      </categories>
      <tags>
        <tag>MQ</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[自动化运维与自动化监控]]></title>
    <url>%2FAuto-Monitor.html</url>
    <content type="text"><![CDATA[互联网公司的运维工作随着互联网的快速发展，运维工作已由传统企业向互联网公司快速变化，然而近几年IaaS、PaaS、SaaS、OaaS等各种平台、云上产品有如雨后春笋般冒出来，很多新人已不知道运维工作包括什么，甚至一些从业人员也逐渐迷失了方向，什么是运维？什么是DevOps？运维需要做什么？一般来讲，无论任何时期任何行业的运维，无非归纳为基础运维、应用运维、运维开发和运维监控四个方向。基础运维大多可理解为传统的IDC、硬件、网络等维护工作；应用维护可理解为系统管理、软件维护、业务系统维护等；运维开发一般只有相对大的公司才会独立设置这么个角色，主要任务是负责运维支撑工具的开发、监控工具开发等工作，例如监控系统、监控脚本、自动化发布工具等；运维监控通常就是24小时的值班人员，他们要时刻关注系统的健康状况，一旦出现问题需要第一时间排查处理，并定其总结过往问题，提出优化方向。 何谓自动化运维所谓自动化运维，就是把运维日常工作中复杂的问题简单化、重复的问题工具化、自动化，尽可能减少人的参与。运维自动化的四个基础组成部份是： CMDB。运维管理的核心，存储所有运维相关数据，包括硬件、系统、软件版本、数据库、中间件、网络配置等信息，所有的维护变更都需要基于这个配置管理数据库。 运行环境标准化。有了CMDB后，就可以通过Puppet、Saltstack、Ansible等自动化管理工具把系统、软件部署标准化。当你只有几十台主机时，可能标准化的作用还是不太明显，但是当你有成百上千台，甚至上万台设备时，要单纯通过人去管理这么多机器无疑是行不通的，你需要合理地运用一些工具去管理你的系统，标准化运行环境。 发布管理。发布管理需要考虑代码自动构建、自动发布、发布后检查、发布异常回滚等，对于生产环境特别是涉及大规模的重大影响变更时，还要考虑灰度发布，尽可能控制用户的影响范围。 监控管理。监控管理包括容量监控、系统运行指标监控、应用指标监控，以及出错时的告警和自动处理。在应用部署完成生产交付后，整个监控系统应当随之同步上线，因为这是运维保障的最后一道防线。 监控系统在运维自动化中的角色如上一章节所说，生产环境各个环节都与监控系统密切相关，没有监控的生产系统跟裸奔没什么区别。而对于运维人员而言，监控系统就相当于他们的双眼，没有它，你没办法知道系统的健康状况。监控系统主要承担的角色有： 采集指标数据。 可视化管理。 异常告警。 协同处理。 回顾分析。 监控系统的理想化模样一个理想的监控系统应当具备以处如下能力： 方便部署。能根据CMDB配置，通过自动化管理工具自动部署，而不需要过多的人为配置。 数据指标采集。能通过模版化、脚本自动化定义监控指标和完成数据采集，并能灵活地支持多种协议上传方式以及多种数据上报格式。 可视化管理。具备数据可视化能力，能通过图表方式展示历史数据的变化，甚至通过可视化界面能清楚知道整个生产环境、各业务流程哪里出现问题，缩小故障时的排查范围和排查时间。 监控告警。当告警或预警事件出现时，能通过短信、邮件、微信等各种媒介进行通知，并支持定义复杂的报警逻辑和级联告警机制，减少不必要的告警，从而提高敏感度。 当故障发生时，能根据设置触发相关处理脚本，实现问题自动修复，甚至做到自动扩容、failover、非核级服务降级等，以确保关键业务的正常运行。 能通过监控系统分析历史故障原因、容量数据变化，能为扩容、环境变更等提供数据依据，也能根据历史记录总结问题的关联性、必然性，最大限度地防止同类问题的再度发生。]]></content>
      <categories>
        <category>monitor</category>
      </categories>
      <tags>
        <tag>monitor</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[物联网应用层协议选择和分析--MQTT、CoAP 、HTTP、XMPP、SoAP]]></title>
    <url>%2FIoT-AppServer-Protocol.html</url>
    <content type="text"><![CDATA[Quick StartMQTT协议MQTT（Message Queuing Telemetry Transport，消息队列遥测传输）最早是IBM开发的一个即时通讯协议，MQTT协议是为大量计算能力有限且工作在低带宽、不可靠网络的远程传感器和控制设备通讯而设计的一种协议。MQTT协议的优势是可以支持所有平台，它几乎可以把所有的联网物品和互联网连接起来。它具有以下主要的几项特性： 使用发布/订阅消息模式，提供一对多的消息发布和应用程序之间的解耦； 消息传输不需要知道负载内容； 使用 TCP/IP 提供网络连接； 有三种消息发布的服务质量：QoS 0：“最多一次”，消息发布完全依赖底层 TCP/IP 网络。分发的消息可能丢失或重复。例如，这个等级可用于环境传感器数据，单次的数据丢失没关系，因为不久后还会有第二次发送。QoS 1：“至少一次”，确保消息可以到达，但消息可能会重复。QoS 2：“只有一次”，确保消息只到达一次。例如，这个等级可用在一个计费系统中，这里如果消息重复或丢失会导致不正确的收费。 小型传输，开销很小（固定长度的头部是 2 字节），协议交换最小化，以降低网络流量； 使用 Last Will 和 Testament 特性通知有关各方客户端异常中断的机制； 在MQTT协议中，一个MQTT数据包由：固定头（Fixed header）、可变头（Variable header）、消息体（payload）三部分构成。MQTT的传输格式非常精小，最小的数据包只有2个bit，且无应用消息头。下图是MQTT为可靠传递消息的三种消息发布服务质量 发布/订阅模型允许MQTT客户端以一对一、一对多和多对一方式进行通讯。下图是MQTT的发布／订阅消息模式 CoAPCoAP是受限制的应用协议(Constrained Application Protocol)的代名词。由于目前物联网中的很多设备都是资源受限型的，所以只有少量的内存空间和有限的计算能力，传统的HTTP协议在物联网应用中就会显得过于庞大而不适用。因此，IETF的CoRE工作组提出了一种基于REST架构、传输层为UDP、网络层为6LowPAN（面向低功耗无线局域网的IPv6）的CoAP协议。CoAP采用与HTTP协议相同的请求响应工作模式。CoAP协议共有4中不同的消息类型。 CON——需要被确认的请求，如果CON请求被发送，那么对方必须做出响应。 NON——不需要被确认的请求，如果NON请求被发送，那么对方不必做出回应。 ACK——应答消息，接受到CON消息的响应。 RST——复位消息，当接收者接受到的消息包含一个错误，接受者解析消息或者不再关心发送者发送的内容，那么复位消息将会被发送。 CoAP消息格式使用简单的二进制格式，最小为4个字节。一个消息 = 固定长度的头部header + 可选个数的option + 负载payload。Payload的长度根据数据报长度来计算主要是一对一的协议 举个例子：比如某个设备需要从服务器端查询当前温度信息。请求消息（CON）： GET /temperature , 请求内容会被包在CON消息里面响应消息 (ACK)： 2.05 Content “22.5 C” ，响应内容会被放在ACK消息里面 CoAP与MQTT的区别MQTT和CoAP都是行之有效的物联网协议，但两者还是有很大区别的，比如MQTT协议是基于TCP，而CoAP协议是基于UDP。从应用方向来分析，主要区别有以下几点： MQTT协议不支持带有类型或者其它帮助Clients理解的标签信息，也就是说所有MQTT Clients必须要知道消息格式。而CoAP协议则相反，因为CoAP内置发现支持和内容协商，这样便能允许设备相互窥测以找到数据交换的方式。 MQTT是长连接而CoAP是无连接。MQTT Clients与Broker之间保持TCP长连接，这种情形在NAT环境中也不会产生问题。如果在NAT环境下使用CoAP的话，那就需要采取一些NAT穿透性手段。 MQTT是多个客户端通过中央代理进行消息传递的多对多协议。它主要通过让客户端发布消息、代理决定消息路由和复制来解耦消费者和生产者。MQTT就是相当于消息传递的实时通讯总线。CoAP基本上就是一个在Server和Client之间传递状态信息的单对单协议。 HTTP协议http的全称是HyperText Transfer Protocol，超文本传输协议，这个协议的提出就是为了提供和接收HTML界面，通过这个协议在互联网上面传出web的界面信息。HTTP协议的两个过程，Request和Response，两个都有各自的语言格式:请求报文格式：1234&lt;method&gt; &lt;request-URL&gt; &lt;version&gt;&lt;headers&gt;&lt;entity-body&gt; 响应报文格式：1234&lt;version&gt; &lt;status&gt; &lt;reason-phrase&gt;&lt;headers&gt;&lt;entity-body&gt; method： 这个很重要，比如说GET和POST方法，这两个是很常用的，GET就是获取什么内容，而POST就是向服务器发送什么数据。当然还有其他的，比如HTTP 1.1中还有：DELETE、PUT、CONNECT、HEAD、OPTIONS、TRACE等一共8个方法（HTTP Method历史：HTTP 0.9 只有GET方法；HTTP 1.0 有GET、POST、HEAD三个方法）。 请求URL: 这里填写的URL是不包含IP地址或者域名的，是主机本地文件对应的目录地址，所以我们一般看到的就是“/”。 版本version： 格式是HTTP/.这样的格式，比如说HTTP/1.1.这个版本代表的就是我们使用的HTTP协议的版本，现在使用的一般是HTTP/1.1 状态码status: 状态码是三个数字，代表的是请求过程中所发生的情况，比如说200代表的是成功，404代表的是找不到文件。 原因短语reason-phrase： 状态码的可读版本，状态码就是一个数字，如果你事先不知道这个数字什么意思，可以先查看一下原因短语。 首部header： 注意这里的header我们不是叫做头，而是叫做首部。可能有零个首部也可能有多个首部，每个首部包含一个名字后面跟着一个冒号，然后是一个可选的空格，接着是一个值，然后换行。 实体的主体部分entity-body： 实体的主体部分包含一个任意数据组成的数据块，并不是所有的报文都包含实体的主体部分，有时候只是一个空行加换行就结束了。 下面我们举个简单的例子：123456789请求报文：GET /index.html HTTP/1.1 Accept: text/*Host: www.myweb.com响应报文：HTTP/1.1 200 OKContent-type: text/plainContent-length: 3 HTTP与CoAP的区别CoAP是6LowPAN协议栈中的应用层协议，基于REST（表述性状态传递）架构风格，支持与REST进行交互。通常用户可以像使用HTTP协议一样用CoAP协议来访问物联网设备。而且CoAP消息格式使用简单的二进制格式，最小为4个字节。HTTP使用报文格式对于嵌入式设备来说需要传输数据太多，太重，不够灵活。 XMPP协议XMPP（可扩展通讯和表示协议）是一种基于可扩展标记语言（XML）的协议，它继承了在XML环境中灵活的发展性。可用于服务类实时通讯、表示和需求响应服务中的XML数据元流式传输。XMPP以Jabber协议为基础，而Jabber是即时通讯中常用的开放式协议。 基本网络结构XMPP中定义了三个角色，客户端，服务器，网关。通信能够在这三者的任意两个之间双向发生。服务器同时承担了客户端信息记录，连接管理和信息的路由功能。网关承担着与异构即时通信系统的互联互通，异构系统可以包括SMS（短信），MSN，ICQ等。基本的网络形式是单客户端通过TCP/IP连接到单服务器，然后在之上传输XML。 功能传输的是与即时通讯相关的指令。在以前这些命令要么用2进制的形式发送（比如QQ），要么用纯文本指令加空格加参数加换行符的方式发送（比如MSN）。而XMPP传输的即时通讯指令的逻辑与以往相仿，只是协议的形式变成了XML格式的纯文本。举个例子:客户端：123456&lt;?xmlversion=&apos;1.0&apos;?&gt;&lt;stream:streamto=&apos;example_com&apos;xmlns=&apos;jabber:client&apos;xmlns:stream=&apos;http_etherx_jabber_org/streams&apos;version=&apos;1.0&apos;&gt; 服务器：1234567&lt;?xmlversion=&apos;1.0&apos;?&gt;&lt;stream:streamfrom=&apos;example_com&apos;id=&apos;someid&apos;xmlns=&apos;jabber:client&apos;xmlns:stream=&apos;http_etherx_jabber_org/streams&apos;version=&apos;1.0&apos;&gt; 工作原理XMPP核心协议通信的基本模式就是先建立一个stream，然后协商一堆安全之类的东西，中间通信过程就是客户端发送XML Stanza，一个接一个的。服务器根据客户端发送的信息以及程序的逻辑，发送XML Stanza给客户端。但是这个过程并不是一问一答的，任何时候都有可能从一方发信给另外一方。通信的最后阶段是关闭流，关闭TCP/IP连接。 SoAP协议SoAP(简单对象访问协议)是交换数据的一种协议规范，是一种轻量的、简单的、基于可扩展标记语言（XML）的协议，它被设计成在WEB上交换结构化的和固化的信息。SOAP 可以和现存的许多因特网协议和格式结合使用，包括超文本传输协议（HTTP），简单邮件传输协议（SMTP），多用途网际邮件扩充协议（MIME）。它还支持从消息系统到远程过程调用（RPC）等大量的应用程序。SOAP使用基于XML的数据结构和超文本传输协议(HTTP)的组合定义了一个标准的方法来使用Internet上各种不同操作环境中的分布式对象。 总结从当前物联网应用发展趋势来分析，MQTT协议具有一定的优势。因为目前国内外主要的云计算服务商，比如阿里云、AWS、百度云、Azure以及腾讯云都一概支持MQTT协议。还有一个原因就是MQTT协议比CoAP成熟的要早，所以MQTT具有一定的先发优势。但随着物联网的智能化和多变化的发展，后续物联网应用平台肯定会兼容更多的物联网应用层协议。 原文：https://blog.csdn.net/acongge2010/article/details/79142380]]></content>
      <categories>
        <category>IoT</category>
      </categories>
      <tags>
        <tag>IoT</tag>
        <tag>物联网</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[常见的的物联网（IoT）协议]]></title>
    <url>%2FIoT-protocol.html</url>
    <content type="text"><![CDATA[许多通信技术是众所周知的，如WiFi，蓝牙，ZigBee和2G ／ 3G ／ 4G蜂窝，但也有几个新兴的新兴网络选项，如线程作为家庭自动化应用的替代品，以及在主要城市实施的空白电视技术用于更广泛的基于IoT的用例。根据应用，范围，数据要求，安全性和功率需求以及电池寿命等因素将决定某种形式的技术组合的选择。这些是向开发人员提供的一些主要通信技术。 Quick StartNB-IoTNB-IoT，Narrow Band Internet of Things，窄带物联网，是一种专为万物互联打造的蜂窝网络连接技术。顾名思义，NB-IoT所占用的带宽很窄，只需约180KHz，而且其使用License频段，可采取带内、保护带或独立载波三种部署方式，与现有网络共存，并且能够直接部署在GSM、UMTS或LTE网络，即2/3/4G的网络上，实现现有网络的复用，降低部署成本，实现平滑升级。NB-IoT具有以下四大特点： 广覆盖。相比现有的GSM、宽带LTE等网络覆盖增强了20dB，信号的传输覆盖范围更大（GSM基站目前理想状况下能覆盖35km），能覆盖到深层地下GSM网络无法覆盖到的地方。其原理主要依靠：1、缩小带宽，提升功率谱密度；2、重复发送，获得时间分集增益。 大连接。相比现有无线技术，同一基站下增多了50-100倍的接入数，每小区可以达到50K连接，真是实现万物互联所必须的海量连接。其原理在于：1、基于时延不敏感的特点，采用话务模型，保存更多接入设备的上下文，在休眠态和激活态之间切换；2、窄带物联网的上行调度颗粒小，资源利用率更高；3、减少空口信令交互，提升频谱密度。 低功耗。终端在99%的时间内均处在休眠态，并集成多种节电技术，待机时间可达10年。1、PSM低功耗模式，即在idle空闲态下增加PSM态 ，相当于关机，由定时器控制呼醒，耗能更低；2、eDRX扩展的非连续接收省电模式，采用更长的寻呼周期，eDRX是DRX耗电量的1/16。 低成本。硬件可剪裁，软件按需简化，确保了NB-IoT的成本低廉，NB-IoT通信单模块成本不足5美元。1234标准：全新的标准协议频率：800 MHz和900 MHz频段范围：N / A数据速率：NB-IoT射频带宽为200kHz。下行速率：大于160kbps，小于250kbps。上行速率：大于160kbps，小于250kbps(Multi-tone)/200kbps(Single-tone)。 详见：「深度剖析」工信部新增NB-IoT 800MHz和900MHz使用频段 GPRSGPRS是通用分组无线服务技术的简称，同时它也是GSM移动电话用户可用的一种移动数据业务，GPRS属于第二代移动通信中的数据传输技术。GPRS可说是GSM的延续。GPRS和以往连续在频道传输的方式不一样，它是以封包式的方式进行传输的，在使用中用户所负担的费用是以传输资料的单位进行计算的。并不是使用其整个频道， GPRS的传输速率可提升至56甚至114Kbps，GPRS具有充分利用现有的网络、传输速率高、资费较合理、资源利用率高、始终在线等特点。1234标准：2G/3G/4G频率：基于移动运营商范围：N / A数据速率：基于物联网卡，常见为56Kbps-114Kbps 蓝牙蓝牙技术是1994年爱立信公司提出的一种近距离无线通信规范，能够在设备之间进行方便快捷、低成本、低功耗的数据和语音传输，是无线个域网（WPAN）的主流技术之一。蓝牙的工作标准基于IEEE802．15．1，工作频段在2．4GHz，信道带宽1MHz，异步非对称连接最高数据速率732．2kbps（蓝牙2．0版支持10Mbps以上的速率），连接距离小于10m，使用高增益天线可是通信范围扩展到100m，由于蓝牙的上述特性使它可以应用于许多无线设备如图像处理设备、智能卡、身份识别设备等。蓝牙技术的缺点是：兼容性和抗干扰能力较差，传输距离较短，成本偏高。1234标准：蓝牙4．2核心规格频率：2．4GHz（ISM）范围：50－150米（智能／ BLE）数据速率：1Mbps（智能／ BLE） ZigbeeZigBee是一种无线连接，可工作在2．4GHz（全球流行）、868MHz（欧洲流行）和915 MHz（美国流行）3个频段上，分别具有最高250kbit／s、20kbit／s和40kbit／s的传输速率，它的传输距离在10—75m的范围内，但可以继续增加。作为一种无线通信技术，ZigBee具有如下特点： 低功耗： 由于ZigBee的传输速率低，发射功率仅为1mW，而且采用了休眠模式，功耗低，因此ZigBee设备非常省电。据估算，ZigBee设备仅靠两节5号电池就可以维持长达6个月到2年左右的使用时间，这是其它无线设备望尘莫及的。 成本低： ZigBee模块的初始成本在6美元左右，估计很快就能降到1．5—2．5美元， 并且ZigBee协议是免专利费的。低成本对于ZigBee也是一个关键的因素。 时延短： 通信时延和从休眠状态激活的时延都非常短，典型的搜索设备时延30ms，休眠激活的时延是15ms， 活动设备信道接入的时延为15ms。因此ZigBee技术适用于对时延要求苛刻的无线控制（如工业控制场合等）应用。 网络容量大： 一个星型结构的Zigbee网络最多可以容纳254个从设备和一个主设备， 一个区域内可以同时存在最多100个ZigBee网络， 而且网络组成灵活。 可靠： 采取了碰撞避免策略，同时为需要固定带宽的通信业务预留了专用时隙，避开了发送数据的竞争和冲突。MAC层采用了完全确认的数据传输模式， 每个发送的数据包都必须等待接收方的确认信息。如果传输过程中出现问题可以进行重发。 安全： ZigBee提供了基于循环冗余校验（CRC）的数据包完整性检查功能，支持鉴权和认证， 采用了AES—128的加密算法，各个应用可以灵活确定其安全属性。 1234标准：基于IEEE802．15．4的ZigBee 3．0频率：2．4GHz范围：10－100米数据速率：250kbps WIFIWIFI即IEEE802．11x，规定了协议的物理层（PHY）和媒体接入控制层（MAC），并依赖TCP／IP作为网络层，Wifi技术主要用来解决办公室局域网和校园网中用户与用户终端的无线接入。IEEE802．11的几个版本包括：802．11a，在5．8GHz频段最高速率54Mbps，在2．4GHz频段速度为1Mbps—11Mbps；802．11g在2．4GHz频段与802．11b兼容，最高速率为54Mbps。WIFI技术的优势在于无线电波覆盖广（100m）网络速度较高，移动性好，厂商进入此门槛低。通常Wifi拥有较高的带宽是以提高功耗为代价的，因此便携WIFI装置需要较高的电能储备，另外WiFi传输的数据质量有待改进，这限制了工业场合的推广。1234标准：基于802．11n（今天最常见的用途）频率：2．4GHz和5GHz频段范围：约50m数据速率：最大600 Mbps，但根据所使用的通道频率和天线数量（最新的802．11－ac标准应提供500Mbps至1Gbps），150－200Mbps更为典型。 Z波(Z－Wave)Z－Wave是一种低功耗射频通信技术，主要用于诸如灯控制器和传感器之类的产品的家庭自动化。针对数据速率高达100kbit ／ s的小数据数据包的可靠和低延迟通信进行了优化，其工作在1GHz频段，并且不受WiFi和其他无线技术在2．4 GHz范围内的干扰，如蓝牙或ZigBee。它支持全网状网络，而不需要协调器节点，并且是非常可扩展的，可以控制多达232个设备。 Z－Wave使用比其他一些更简单的协议，可以实现更快更简单的开发，但与其他无线技术（如ZigBee等）的多种来源相比，唯一的芯片制造商是Sigma Designs。1234标准：Z－Wave Alliance ZAD12837 ／ ITU－T G．9959频率：900MHz（ISM）范围：30m数据速率：9．6 ／ 40 ／ 100kbit ／ s 6LowPAN基于IP（Internet Protocol）的技术是6LowPAN（IPv6低功率无线个人区域网络）。 6LowPAN不是像蓝牙或ZigBee这样的IoT应用协议技术，而是一种定义封装和头压缩机制的网络协议。该标准具有频带和物理层的自由度，也可以在多种通信平台上使用，包括以太网，Wi－Fi，802．15．4和sub－1GHz ISM。一个关键的属性是IPv6（互联网协议版本6）堆栈，这是近年来非常重要的介绍，以实现物联网。 IPv6是IPv4的后继者，为世界上每个人提供大约5 x 1028个地址，使世界上任何嵌入式对象或设备都拥有自己的唯一IP地址并连接到互联网。例如，IPv6专为家庭或楼宇自动化设计，提供了一种基本的传输机制，可以通过低功耗无线网络以成本效益的方式生产复杂的控制系统和与设备进行通信。该标准旨在通过基于IEEE802．15．4的网络发送IPv6数据包，并实施开放IP标准，包括TCP，UDP，HTTP，COAP，MQTT和Websockets，该标准提供端对端可寻址节点，允许路由器将网络连接到IP。 6LowPAN是一种网状网络，具有强大的可扩展性和自愈性。网状路由器设备可以路由指定给其他设备的数据，而主机能够长时间睡眠。这里有6LowPAN的解释，TI提供。1234标准：RFC6282频率：（适用于各种其他网络媒体，包括蓝牙智能（2．4GHz）或ZigBee或低功率射频（亚1GHz）范围：N ／ A数据速率：N ／ A 线程线程是一种针对家庭自动化环境的新型基于IP的IPv6网络协议。基于6LowPAN，也喜欢它，它不是像蓝牙或ZigBee这样的IoT应用协议。然而，从应用的角度来看，它主要被设计为WiFi的补充，因为它识别出WiFi对于许多消费者设备而言是有利的，它在家庭自动化设置中使用的限制。线程组于2014年中推出，免版税协议基于各种标准，包括IEEE802．15．4（作为无线空中接口协议），IPv6和6LoWPAN，并为物联网提供了一种弹性的基于IP的解决方案。 Thread专为从现有的IEEE802．15．4无线芯片供应商（如飞思卡尔和Silicon Labs）工作，Thread支持使用IEEE802．15．4无线电收发器的网状网络，能够处理多达250个具有高级别身份验证和加密的节点。相对简单的软件升级应允许用户在现有的支持IEEE802．15．4的设备上运行线程。1234标准：线程，基于IEEE802．15．4和6LowPAN频率：2．4GHz（ISM）范围：N ／ A数据速率：N ／ A 蜂窝需要更长距离运行的IoT应用程序可以利用GSM ／ 3G ／ 4G蜂窝通信功能。虽然蜂窝电话显然能够发送大量的数据，特别是对于4G，但对于许多应用来说，费用和功耗将会太高，但是对于传输速度非常低的基于传感器的低带宽数据项目来说，这是非常理想的互联网上的数据量。该领域的一个关键产品是SparqEE系列产品，包括原始的小型CELLv1．0低成本开发板和一系列与Raspberry Pi和Arduino平台一起使用的屏蔽连接板。1234标准：GSM ／ GPRS ／ EDGE（2G），UMTS ／ HSPA（3G），LTE（4G）频率：900／1800／1900 ／ 2100MHz范围：GSM最大35km； HSPA最长200公里数据速率（典型下载）：35－170kps（GPRS），120－384kbps（EDGE），384Kbps－2Mbps（UMTS），600kbps－10Mbps（HSPA），3－10Mbps NFCNFC（近场通信）是一种技术，能够实现电子设备之间的简单和安全的双向交互，特别适用于智能手机，允许消费者执行非接触式支付交易，访问数字内容和连接电子设备。本质上它扩展了非接触式卡技术的能力，并使设备能够在距离小于4cm的情况下共享信息。此处提供更多信息。1234标准：ISO ／ IEC 18000－3频率：13．56MHz（ISM）范围：10厘米数据速率：100－420kbps SigfoxSigfox的范围在WiFi和蜂窝之间。它使用可免费使用的ISM频带，而不需要获取许可证，以便在非常窄的频谱范围内将数据传输到连接对象和从连接对象传输数据。 Sigfox的想法是，对于运行在小型电池上的许多M2M应用程序，只需要低级别的数据传输，则WiFi的范围太短，而蜂窝电话太贵，并且功耗太大。 Sigfox使用一种称为超窄带（UNB）的技术，仅用于处理每秒10至1，000位的低数据传输速度。与5000微瓦相比，蜂窝通信消耗的电量仅为50微瓦，或者可以通过2．5Ah电池提供典型的待机时间20年，而蜂窝电话仅为0．2年。已经部署在成千上万个连接对象中，该网络目前正在欧洲主要城市推出，其中包括英国的十个城市。该网络提供了一个强大的，功率高效和可扩展的网络，可以与数百万个电池供电设备在几平方公里的区域进行通信，使其适用于预期包括智能电表，病人监视器，安全设备，街道照明和环境传感器。 Sigfox系统使用Silicon Labs等EZRadioPro无线收发器等硅片，为在1GHz以下频段工作的无线网络应用提供行业领先的无线性能，扩展范围和超低功耗。1234标准：Sigfox频率：900MHz范围：30－50公里（农村环境），3－10公里（城市环境）数据速率：10－1000bps Neul与Sigfox相似，在1GHz频段内运行，Neul利用电视白空间频谱的小片，提供高可扩展性，高覆盖率，低功耗和低成本无线网络。系统基于Iceni芯片，其使用白色空间无线电进行通信，以访问高质量的UHF频谱，由于模拟到数字电视转换，现在可用。通信技术称为无重量，是一种为IoT设计的新型广域无线网络技术，与现有的GPRS，3G，CDMA和LTE WAN解决方案大有竞争。数据速率可以是在同一个单一链路上从每秒几位到100kbps的任何数据速率；并且设备可以从2xAA电池消耗少至20至30mA，这意味着在现场10至15年。1234标准：Neul频率：900MHz（ISM），458MHz（英国），470－790MHz（白色空间）范围：10公里数据速率：最少可达100kbps LoRaWANAgain在某些方面与Sigfox和Neul类似，LoRaWAN针对广域网（WAN）应用，旨在为具有特定功能的低功率WAN提供支持，以便在IoT，M2M和M2M中支持低成本移动安全双向通信智能城市和工业应用。针对低功耗优化并支持具有数百万和数百万台设备的大型网络，数据速率范围为0．3 kbps至50 kbps。1234标准：LoRaWAN频率：各种范围：2－5公里（城市环境），15公里（郊区环境）数据速率：0．3－50 kbps。]]></content>
      <categories>
        <category>IoT</category>
      </categories>
      <tags>
        <tag>IoT</tag>
        <tag>物联网</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[vim多文件之间的切换]]></title>
    <url>%2Fvim-multiple-files.html</url>
    <content type="text"><![CDATA[Quick Start打开多个文件 vim还没有启动的时候:12在终端里直接打开所有想要打开的文件vim file1 file2 ... filen vim启动打开多个文件: 12在编辑模式输入:e file 同时显示多个文件: 12:sp //水平切分窗口:vsplit //垂直切分窗口 在文件之间切换 一个文件切换到其他文件 12345Ctrl+6 //两文件间的切换:bn //下一个文件:bp //上一个文件:ls //列出打开的文件，带编号:b1~n //切换至第n个文件 在窗格间切换的方法对于用(v)split在多个窗格中打开的文件，这种方法只会在当前窗格中切换不同的文件。 123Ctrl+w+方向键——切换到前／下／上／后一个窗格Ctrl+w+h/j/k/l ——同上Ctrl+ww——依次向后切换到下一个窗格中]]></content>
      <categories>
        <category>vim</category>
      </categories>
      <tags>
        <tag>vim</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux终端常用的快捷键]]></title>
    <url>%2FTerminal-Shortcut-keys.html</url>
    <content type="text"><![CDATA[Linux中的许多操作在终端（Terminal）中十分的快捷，记住一些快捷键的操作更得心应手。在Ubuntu中打开终端的快捷键是Ctrl+Alt+T。其他的一些常用的快捷键如下： 快捷键 功能 Tab 自动补全 Ctrl+a 光标移动到开始位置 Ctrl+e 光标移动到最末尾 Ctrl+k 删除此处至末尾的所有内容 Ctrl+u 删除此处至开始的所有内容 Ctrl+d 删除当前字符 Ctrl+h 删除当前字符前一个字符 Ctrl+w 删除此处到左边的单词 Ctrl+y 粘贴由Ctrl+u， Ctrl+d， Ctrl+w删除的单词 Ctrl+l 相当于clear，即清屏 Ctrl+r 查找历史命令 Ctrl+b 向回移动光标 Ctrl+f 向前移动光标 Ctrl+t 将光标位置的字符和前一个字符进行位置交换 Ctrl+&amp; 恢复 ctrl+h 或者 ctrl+d 或者 ctrl+w 删除的内容 Ctrl+S 暂停屏幕输出 Ctrl+Q 继续屏幕输出 Ctrl+Left-Arrow 光标移动到上一个单词的词首 Ctrl+Right-Arrow 光标移动到下一个单词的词尾 Ctrl+p 向上显示缓存命令 Ctrl+n 向下显示缓存命令 Ctrl+d 关闭终端 Ctrl+xx 在EOL和当前光标位置移动 Ctrl+x@ 显示可能hostname补全 Ctrl+c 终止进程/命令 Shift+上或下 终端上下滚动 Shift+PgUp/PgDn 终端上下翻页滚动 Ctrl+Shift+n 新终端 alt+F2 输入gnome-terminal打开终端 Shift+Ctrl+T 打开新的标签页 Shift+Ctrl+W 关闭标签页 Shift+Ctrl+C 复制 Shift+Ctrl+V 粘贴 Alt+数字 切换至对应的标签页 Shift+Ctrl+N 打开新的终端窗口 Shift+Ctrl+Q 管壁终端窗口 Shift+Ctrl+PgUp/PgDn 左移右移标签页 Ctrl+PgUp/PgDn 切换标签页 F1 打开帮助指南 F10 激活菜单栏 F11 全屏切换 Alt+F 打开 “文件” 菜单（file） Alt+E 打开 “编辑” 菜单（edit） Alt+V 打开 “查看” 菜单（view） Alt+S 打开 “搜索” 菜单（search） Alt+T 打开 “终端” 菜单（terminal） Alt+H 打开 “帮助” 菜单（help）]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ubuntu操作系统通过saltstack安装nginx]]></title>
    <url>%2Fsaltstack-install-nginx.html</url>
    <content type="text"><![CDATA[Quick Start新建nginx的state.sls文件12345678910nginx: pkgrepo.managed: - name: deb http://nginx.org/packages/ubuntu/ &#123;&#123;grains[&apos;oscodename&apos;]&#125;&#125; nginx - key_url: http://nginx.org/keys/nginx_signing.key - refresh_db: true - require_in: - pkg: nginx pkg.installed: - name: nginx 测试运行结果123456789101112131415161718192021222324252627salt &apos;*&apos; state.sls nginx test=Trueminion1:---------- ID: nginx Function: pkgrepo.managed Name: deb http://nginx.org/packages/ubuntu/ xenial nginx Result: None Comment: Package repo &apos;deb http://nginx.org/packages/ubuntu/ xenial nginx&apos; will be configured. This may cause pkg states to behave differently than stated if this action is repeated without test=True, due to the differences in the configured repositories. Started: 23:49:18.727125 Duration: 96.173 ms Changes:---------- ID: nginx Function: pkg.installed Result: None Comment: The following packages would be installed/updated: nginx Started: 23:49:22.886030 Duration: 3786.682 ms Changes:Summary for minion1------------Succeeded: 2 (unchanged=2)Failed: 0------------Total states run: 2Total run time: 3.883 s]]></content>
      <categories>
        <category>saltstack</category>
      </categories>
      <tags>
        <tag>saltstack</tag>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ubuntu操作系统通过saltstack安装docker]]></title>
    <url>%2Fsaltstack-install-docker.html</url>
    <content type="text"><![CDATA[Quick StartDocker是一个开源的应用容器引擎，基于Go语言并遵从Apache2.0协议开源，源代码部署在GitHub上，现已被广泛使用。常规情况下，Docker作为基础组件打在os的镜像里，对于后期加入管理的主机可通过saltstack进行批量安装。 新建docker的state.sls文件12345678910111213141516171819202122repository: pkg.installed: - pkgs: - apt-transport-https - curl - ca-certificates - software-properties-common - refresh: Truedocker-ce: pkgrepo.managed: - name: deb [arch=amd64] https://download.docker.com/linux/ubuntu &#123;&#123;grains[&apos;oscodename&apos;]&#125;&#125; stable - key_url: https://download.docker.com/linux/ubuntu/gpg - refresh_db: true - require: - pkg: repository - require_in: - pkg: docker-ce pkg.installed: - name: docker-ce - refresh: True 测试执行结果1234567891011121314151617181920212223242526272829303132333435salt &apos;*&apos; state.sls docker test=Trueminion1:---------- ID: repository Function: pkg.installed Result: None Comment: The following packages would be installed/updated: software-properties-common, apt-transport-https Started: 23:30:54.553191 Duration: 3797.25 ms Changes:---------- ID: docker-ce Function: pkgrepo.managed Name: deb [arch=amd64] https://download.docker.com/linux/ubuntu xenial stable Result: None Comment: Package repo &apos;deb [arch=amd64] https://download.docker.com/linux/ubuntu xenial stable&apos; will be configured. This may cause pkg states to behave differently than stated if this action is repeated without test=True, due to the differences in the configured repositories. Started: 23:30:58.355189 Duration: 114.982 ms Changes:---------- ID: docker-ce Function: pkg.installed Result: None Comment: The following packages would be installed/updated: docker-ce Started: 23:30:58.470868 Duration: 56.745 ms Changes:Summary for minion1------------Succeeded: 3 (unchanged=3)Failed: 0------------Total states run: 3Total run time: 3.969 s]]></content>
      <categories>
        <category>saltstack</category>
      </categories>
      <tags>
        <tag>saltstack</tag>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[yum install nginx]]></title>
    <url>%2Fyum-install-nginx.html</url>
    <content type="text"><![CDATA[Quick Start新增nginx.repo文件cat /etc/yum.repos.d/nginx.repo12345[nginx]name=nginx repobaseurl=http://nginx.org/packages/centos/$releasever/$basearch/gpgcheck=0enabled=1 安装nginx1yum install nginx]]></content>
      <categories>
        <category>nginx</category>
      </categories>
      <tags>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux设置默认编辑器]]></title>
    <url>%2FLinux-Set-Default-Editor.html</url>
    <content type="text"><![CDATA[Quick StartLinux设置默认编辑器为vi在使用edquota编辑限额时出现错误：1edquota: cannot exec /usr/bin/editor 根据错误提示，edquota命令没有找到可用的编辑器，于是设置系统默认的编辑器。在linux 中设置默认编辑器为vi1export EDITOR=vi]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>vi</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux查看操作系统版本]]></title>
    <url>%2FLinux-Get-OS-Release.html</url>
    <content type="text"><![CDATA[Quick StartUbuntulsb_release -a12345No LSB modules are available.Distributor ID: UbuntuDescription: Ubuntu 14.04.1 LTSRelease: 14.04Codename: trusty Centos方法一cat /etc/issue12CentOS release 6.8 (Final)Kernel \r on an \m 方法二cat /etc/redhat-release1CentOS release 6.8 (Final)]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[apt-get install JDK8]]></title>
    <url>%2Fapt-get-install-JDK8.html</url>
    <content type="text"><![CDATA[Quick Start安装python-software-properties12sudo apt-get install python-software-propertiessudo apt-get install software-properties-common 首先添加ppa1sudo add-apt-repository ppa:webupd8team/java 然后更新系统1sudo apt-get update 最后开始安装12345sudo apt-get install oracle-java8-installerjava -versionjava version “1.8.0_05&quot;Java(TM) SE Runtime Environment (build 1.8.0_05-b13) Java HotSpot(TM) Server VM (build 25.5-b02, mixed mode) java版本切换1sudo update-java-alternatives -s java-8-oracle]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>JDK8</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[阿里云yum仓库镜像安装kubernetes]]></title>
    <url>%2Faliyum-install-kubernetes.html</url>
    <content type="text"><![CDATA[Quick Start安装kubernetes的时候，需要安装kubelet, kubeadm等包，但k8s官网给的yum源是packages.cloud.google.com，国内访问不了，此时我们可以使用阿里云的yum仓库镜像。注意不要开启check。 12345678910cat &lt;&lt;EOF &gt; /etc/yum.repos.d/kubernetes.repo[kubernetes]name=Kubernetesbaseurl=http://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64enabled=1gpgcheck=0repo_gpgcheck=0gpgkey=http://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg http://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpgEOF]]></content>
      <categories>
        <category>Kubernetes</category>
      </categories>
      <tags>
        <tag>Kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mac install Kubernetes]]></title>
    <url>%2Fmac-install-Kubernetes.html</url>
    <content type="text"><![CDATA[Quick Start解决mac docker启动不了Kubernetes的问题docker for mac edge版新增了Kubernetes功能。但由于墙的问题，启动Kubernetes时，一直显示Kubernetes is starting.解决方法参考：https://github.com/maguowei/k8s-docker-for-mac docker版本： 先安装以上EDGE版如已安装，恢复出厂设置，参考docker官方文档。 配置本地私服Registry mirrors里增加http://registry.docker-cn.com， 注意不要用https，否则会提示证书错误 打开命令行工具，执行123git clone https://github.com/maguowei/k8s-docker-for-mac.gitcd k8s-docker-for-mac/./load_images.sh 按下图打勾，勾选k8s]]></content>
      <categories>
        <category>Kubernetes</category>
      </categories>
      <tags>
        <tag>Kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[运维工作思考]]></title>
    <url>%2Fops.html</url>
    <content type="text"><![CDATA[前言&emsp;&emsp;这两年随着公司在各行业领域的深入以及运营策略的调整，平台业务量有了突飞猛进的增长。在实际运维过程中，因为业务系统越来越复杂，变更越来越频繁，总是存在各种各样监控未覆盖或者以前未知的故障发生，服务器也是处理野蛮增长的状态，然而运维还停留在“刀耕火种”的原始状态。&emsp;&emsp;在这种工作方式下，服务器的安装、初始化，软件部署、服务发布和监控都是通过手动方式来完成的，需要运维人员登录到服务器上，一台一台去管理和维护。这种非并发的线性工作方式是制约效率的最大障碍。同时，因为手动的操作方式过于依赖运维人员的执行顺序和操作步骤，稍有不慎即可能导致服务器配置不一致，对于数据库或MQ的误操作甚至会带来灾难性的故障，即便现在用了docker，也写了一些自动化的脚本提升工作效率和质量，但充其量也只是个“石器时代”的DevOps。 解决方向&emsp;&emsp;现阶段，无论项目层面还是运维层面，都有三个大方向的问题需要解决： 质量运维完成质量体现在可用性(是否稳定、用户体验是否友好）、规范性、安全性(除了防范攻击以外，还包括应急容灾等），其中，对于一个已上线的商用平台稳定性尤其重要，稳定是1，其他都是0。 效率由于运维人员和其他职能线条的人员比例不匹配，对于基础设施的交付、中间件的交付，代码发布、故障的处理、定制化项目的交付等，如何使这些任务完成更高效，这是运维人员面临的主要问题。 成本在项目上运维部门往往被定位为消耗部门，实际交付过程中运维费用往往包含在开发费用里，如何通过最少的人力完成SLA是运维部门帮项目赚钱的唯一方法。另外，项目越大往往服务器等成本支出就越大，然而这个增长比例不一定是正确的，所以运维成本最核心要解决的是搞清楚具体钱花在哪个方向，并对这些成本问题进行优化。 解决方案技术层面解决&emsp;&emsp;合理利用CMDB、监控、流程、自动化工具和日志分析工具解决质量、效率、成本问题。 质量层面1.1 梳理系统短板，加强处理。通过CMDB(配置管理数据库)，梳理服务间的依赖关系，找出强依赖核心模块，排查单点模块，梳理参数配置的合理性，重点保障和优化。例如mysql、mongo、redis、rabbitmq等。1.2 对现有监控进行查漏补缺。主要体现在： 现有监控系统的覆盖范围，核心业务模块、主机、中间件、数据库等是否有覆盖。 监控方法的有效性，是否包含了核心指标的监控，是否有利于故障排查和日常分析，能否会对生产系统无感知监控。 告警策略的合理性和有效性，包括告警渠道的使用是否合理、告警内容是否清晰、升级机制是否合理、避免短信轰炸等。 1.3 通过流程提高运维质量。虽然现在都在提倡DevOps，但必要的流程是质量把控的主要手段，能让大家知道什么时候做什么、怎么做。(参考ITIL管理机制) 故障处理流程：重点确定故障处理时的熔断机制。 变更发布流程：重点评估影响范围、操作顺序、回退机制涉及的数据和配置以及发布的时间窗口。评审的依据应以CMDB配置管理为基础，基于业务流程和边界服务一起评估。 事件处理流程：由于一般的中小型公司运维人员严重不足，也没有业务方向的客服人员，所以在事件处理流程的基础上，应重点设计事件和服务请求的定义，处理的时间窗口、事件的升级机制等。 1.4 应急容灾系统的建设很多公司不一定有条件做灾备系统，这和成本、技术架构、服务级别都有关系，但在系统部署和架构设计时应考虑扩容和容灾能力，底层数据库、中间件应做好备份，部份服务可考虑提前做好异地多活，以便故障发生时可在其他快速复制一套环境提供服务。1.5 自动化运维工具的落地&emsp;$emsp;重要性无需质疑，除了运维批处理操作以外，还需要考虑自动化测试工具，以及故障时的常规操作脚本，避免误操作带来的二次故障。 效率层面2.1 合理利用云上产品。由于人员不足以及能力上的欠缺，合理利用云上服务能大大降低运维成本，让云维人员把精力更多的放在运维工作上。2.2 运维工具的使用。市面上已有很多成熟的运维工具可以使用，如zabbix、ELK、Ansible、Saltstack等等，运维人员无需重复去制造轮子，应把精力花在如何用好工具，而不是增加多一套维护成本。与此同时，对于流程上确定的一些故障处理办法、版本发布方法，备份管理办法等，运维人员可优先开发相关脚本或工具，在提高操作效率的同时，也降低了学习成本和操作风险。2.3 让系统助自一定自愈能力。为解决人力问题，运维除了在日常的操作上让系统具备自动化能力，同时，可重点对于故障处理里程里定义的重启、failover、空间清理等标准操作做成自动化，当监控触发告警时，让系统具备一定的自我恢复能力，从而减少故障影响时长。 成本层面3.1 分析服务器费用占比，分析成本的合理性。3.2 通过CMDB和监控平台分析主机的性能情况和应用部署的合理性，对于不合理的部署项目上进行优化。3.3 完善业务日志，对每笔业务形成链路追踪，分析每笔业务的费用占比，对费用占比大但使用率少的业务模块进行部署调整，或从产品层面对功能进行优化，甚至关闭。 管理层面解决&emsp;&emsp;大部份公司都在推行DevOps的模式，但是核心理念并不在于让开发处理运维的工作，所以运维团队更多的职责是为开发团队提供运维的能力，与此同时，运维人员需在文档、工具层面做出更多的沉淀，尽可能弱化人的重要性。&emsp;&emsp;运维团队的管理主要体现在以下几点： 责任到人。可按业务维度分配到个人，对于核心的业务模块和业务流程所有人必须共同承担。 每个人必须掌握业务领域中用到的服务、数据库、中间件等维护技能，对公共的基础服务每个人都需掌握基本的维护技能。 每个人每个月必须对自己负责的业务模块和基础服务提出问题并优化，如需开发人员或产品人员解决的问题需跟进处理进度,优先从事件工单提取最常见问题加以优化。 每个每个月需完成一篇知识库，并评审通过。 采取轮岗机制，每个人需要对其他人负责的业务模块加以学习，并通过考核。]]></content>
      <categories>
        <category>运维心得</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Ubuntu 16.04 install mysql5.7]]></title>
    <url>%2FUbuntu-16-04-install-mysql5-7.html</url>
    <content type="text"><![CDATA[Quick Start在Ubuntu 16.04版本的mysql数据库，默认是5.7版本的；123sudo apt-get updatesudo apt-get install mysql-server sudo mysql_secure_installation 更改数据库存储目录想要修改MySQL数据库存储的目录，需要了解mysql配置文件，以及apparmor的配置文件,这里提一下apparnor 是控制访问权限的，而mysql依赖它，所以不单单是改完mysql配置文件的内容，同样的需要修改apparmor的相应的配置文件。 创建MySQL另外存储的目录123mkdir /database/mysqlchmod 700 /database/mysqlchowd mysql:mysq /database/mysql 将以前的数据库复制到新的存储目录这样避免了再次初始化，并且数据还在1cp -av /var/lib/mysql/* /database/mysql 删除日志不删除会报错12rm -rf /database/mysql/ib_logfile0rm -rf /database/mysql/ib_logfile1 修改my.cnf12vim /etc/mysql/my.cnf 修改datadir=/var/lib/mysql 为你需要修改的目录 这里是 datadir=/database/mysql 修改apparmor的配置文件1234567vim /etc/apparmor/usr.sbin.mysqld将 /var/lib/mysql/ r, /var/lib/mysql/** rwk,修改为 /database/mysql/ r, /database/mysql/** rwk, reload apparmor的配置并重启这里不要停止apparmor服务，因为我在测试的时候关闭以后修改配置文件后反到是不成功， 直接修改后reload 然后重启12service apparmor reload service apparmor restart 重启mysql1service mysql restart 验证mysql的目录是否已经更改12进入mysql 命令行,执行：show variables like &apos;%datadir%’; 如果启动不了， 查看/var/log/mysql/error.log如果出现： InnoDB: The innodb_system data file ‘ibdata1’ must be writable 请仔细核对第5步，第6步如果出现启动成功，但是测试新建数据库还是在原来的目录， 试试重启服务器，或者仔细查看mysql配置文件，提醒一下 并不需要更改/usr/share/mysql/mysql-systemd-start 脚本中的datadir变量]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zabbix-sender使用场景]]></title>
    <url>%2Fzabbix-sender.html</url>
    <content type="text"><![CDATA[Quick Start使用zabbix监控类型zabbix trapper，需要配合zabbix_sender给它传递数据，上报频率由客户端控制，通常用crontab来设置定时作业。一般情况下zabbix_sender会在以下几种场景使用： 执行超长时间脚本。这种情况下使用主动或被动模式都会超时，必须改成让客户端提交数据的方式。 客户端脚本一次执行得到多项采集数据时，通过zabbix_sender可以一次性上报多条结果，减少调用次数。 执行后数据有逻辑关和严谨性的，必须改成让客户端提交数据的方式，如取同一时刻的生产量和消耗量。 zabbix_sender命令详解语法： usage: zabbix_sender [-Vhv] {[-zpsI] -ko | [-zpI] -T -i &lt;file&gt; -r} [-c &lt;file&gt;] 使用参数： 1234567891011-c --config &lt;file&gt; 配置文件绝对路径-z --zabbix-server &lt;server&gt; zabbix server的IP地址-p --port &lt;server port&gt; zabbix server端口.默认10051-s --host &lt;hostname&gt; 主机名，zabbix里面配置的主机名（不是服务器的hostname），不能使用ip地址-I --source-address &lt;IP address&gt; 源IP-k --key &lt;key&gt; 监控项的key-o --value &lt;key value&gt; key值-i --input-file &lt;input file&gt; 从文件里面读取hostname、key、value 一行为一条数据，使用空格作为分隔符，如果主机名带空格，那么请使用双引号包起来-T --with-timestamps 一行一条数据，空格作为分隔符: &lt;hostname&gt; &lt;key&gt; &lt;timestamp&gt; &lt;value&gt;，配合 --input-file option，timestamp为unix时间戳-r --real-time 将数据实时提交给服务器-v --verbose 详细模式, -vv 更详细 zabbix_sender使用实例客户端主机为RedisServer，服务端IP为192.168.1.2，redis info 得到信息如下： 123456789……＃Clientsconnected_clients:2129client_longest_output_list:0client_biggest_input_buf:0blocked_clients:6…… 我们把clients的信息上传给zabbix server，zabbix item配置如下(其它值默认)： redis connected_clients: 1234567type: Zabbix trapperKey: redis.info[connected_clients]Type of information: Numberic (unsigned)Data type: Decimal redis client_longest_output_list: 1234567type: Zabbix trapperKey: redis.info[client_longest_output_list]Type of information: Numberic (unsigned)Data type: Decimal redis client_biggest_input_buf: 1234567type: Zabbix trapperKey: redis.info[client_biggest_input_buf]Type of information: Numberic (unsigned)Data type: Decimal redis blocked_clients: 1234567type: Zabbix trapperKey: redis.info[blocked_clients]Type of information: Numberic (unsigned)Data type: Decimal 1､ 提交单条数据： 1234zabbix_sender -s &quot;RedisServer&quot; -z 192.168.1.2 -k &quot;redis.info[connected_clients]&quot; -o 2129 -r`zabbix_sender -s &quot;RedisServer&quot; -z 192.168.1.2 -k &quot;redis.info[client_longest_output_list]&quot; -o 0 -r`zabbix_sender -s &quot;RedisServer&quot; -z 192.168.1.2 -k &quot;redis.info[client_biggest_input_buf]&quot; -o 0 -r`zabbix_sender -s &quot;RedisServer&quot; -z 192.168.1.2 -k &quot;redis.info[blocked_clients]&quot; -o 6 -r` 2、 指量提交数据： 123456789＃ cat redis_info.txt&quot;RedisServer&quot; &quot;redis.info[connected_clients]&quot; 2129&quot;RedisServer&quot; &quot;redis.info[client_longest_output_list]&quot; 0&quot;RedisServer&quot; &quot;redis.info[client_biggest_input_buf]&quot; 0&quot;RedisServer&quot; &quot;redis.info[blocked_clients]&quot; 6zabbix_sender -z 192.168.1.2 -i redis_info.txtinfo from server: &quot;processed: 4; failed: 0; total: 4; seconds spent: 0.000085&quot;sent: 4; skipped: 0; total: 4]]></content>
      <categories>
        <category>zabbix</category>
      </categories>
      <tags>
        <tag>zabbix</tag>
      </tags>
  </entry>
</search>
